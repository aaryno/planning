{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "notebook-intro",
   "metadata": {},
   "source": [
    "# üó∫Ô∏è Spatial Data Exploration with GeoPandas\n",
    "\n",
    "**GIST 604B - Module 5: Python GIS Programming**\n",
    "\n",
    "Welcome to your interactive spatial data exploration notebook! This notebook will help you:\n",
    "\n",
    "- üìÇ Load spatial data from different file formats\n",
    "- üîç Explore spatial properties and characteristics\n",
    "- ‚úÖ Validate and fix common spatial data issues\n",
    "- üåê Handle coordinate reference systems (CRS)\n",
    "- üé® Create basic visualizations\n",
    "\n",
    "## üöÄ Getting Started\n",
    "\n",
    "This notebook is your **development playground**. Use it to:\n",
    "1. Test your functions from `src/geopandas_analysis/spatial_data_loading.py`\n",
    "2. Experiment with different spatial datasets\n",
    "3. Debug and refine your implementations\n",
    "4. Create visualizations to understand your data\n",
    "\n",
    "**Remember**: Once your code works here, copy it to the appropriate `.py` files!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Imports\n",
    "\n",
    "Let's start by importing all the libraries we need and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core spatial analysis libraries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Optional: Advanced visualization and basemaps\n",
    "try:\n",
    "    import contextily as ctx\n",
    "    print(\"‚úÖ Contextily available for basemaps\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Contextily not available - no basemaps\")\n",
    "\n",
    "try:\n",
    "    import folium\n",
    "    print(\"‚úÖ Folium available for interactive maps\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Folium not available - no interactive maps\")\n",
    "\n",
    "# Sample datasets\n",
    "try:\n",
    "    import geodatasets\n",
    "    print(\"‚úÖ GeoDatasetsavailable for sample data\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Geodatasets not available - will create our own sample data\")\n",
    "\n",
    "# System and utility libraries\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "# Configure display and warnings\n",
    "plt.style.use('default')\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print(\"üó∫Ô∏è All libraries loaded successfully!\")\n",
    "print(f\"üìç GeoPandas version: {gpd.__version__}\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-functions",
   "metadata": {},
   "source": [
    "## üîß Import Your Functions\n",
    "\n",
    "Now let's import the functions you're implementing. If you get import errors, it means you need to implement these functions in the corresponding `.py` files first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "function-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the src directory to Python path so we can import our functions\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "try:\n",
    "    from geopandas_analysis.spatial_data_loading import (\n",
    "        load_spatial_dataset,\n",
    "        explore_spatial_properties,\n",
    "        validate_spatial_data,\n",
    "        standardize_crs\n",
    "    )\n",
    "    print(\"‚úÖ Successfully imported all spatial data loading functions!\")\n",
    "    functions_available = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Could not import functions: {e}\")\n",
    "    print(\"üí° Implement the functions in src/geopandas_analysis/spatial_data_loading.py first!\")\n",
    "    functions_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sample-data-section",
   "metadata": {},
   "source": [
    "## üìä Create Sample Spatial Data\n",
    "\n",
    "Let's create some sample spatial data to work with. This will help you understand different geometry types and test your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-sample-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample point data (like cities or weather stations)\n",
    "sample_points = gpd.GeoDataFrame({\n",
    "    'name': ['Phoenix', 'Tucson', 'Flagstaff', 'Yuma', 'Prescott'],\n",
    "    'population': [1680000, 548073, 76831, 95548, 45827],\n",
    "    'elevation_ft': [1086, 2389, 6910, 138, 5368],\n",
    "    'geometry': [\n",
    "        Point(-112.074, 33.449),   # Phoenix\n",
    "        Point(-110.926, 32.221),   # Tucson\n",
    "        Point(-111.651, 35.198),   # Flagstaff\n",
    "        Point(-114.627, 32.693),   # Yuma\n",
    "        Point(-112.468, 34.540)    # Prescott\n",
    "    ]\n",
    "}, crs='EPSG:4326')\n",
    "\n",
    "# Create sample polygon data (like counties or regions)\n",
    "sample_polygons = gpd.GeoDataFrame({\n",
    "    'county_name': ['Maricopa', 'Pima', 'Coconino'],\n",
    "    'area_sq_miles': [9224, 9189, 18661],\n",
    "    'population_2020': [4485414, 1043433, 145101],\n",
    "    'geometry': [\n",
    "        # Simplified county boundaries (just for demonstration)\n",
    "        Polygon([(-113.0, 33.0), (-111.0, 33.0), (-111.0, 34.0), (-113.0, 34.0)]),  # Maricopa\n",
    "        Polygon([(-111.5, 31.5), (-110.0, 31.5), (-110.0, 33.0), (-111.5, 33.0)]),  # Pima\n",
    "        Polygon([(-112.5, 34.5), (-110.5, 34.5), (-110.5, 36.5), (-112.5, 36.5)])   # Coconino\n",
    "    ]\n",
    "}, crs='EPSG:4326')\n",
    "\n",
    "# Create sample line data (like roads or rivers)\n",
    "sample_lines = gpd.GeoDataFrame({\n",
    "    'name': ['I-10 West', 'I-17 North', 'US-60 East'],\n",
    "    'highway_type': ['Interstate', 'Interstate', 'US Highway'],\n",
    "    'length_miles': [391, 146, 369],\n",
    "    'geometry': [\n",
    "        LineString([(-114.0, 32.7), (-112.0, 33.4), (-110.0, 32.2)]),  # I-10\n",
    "        LineString([(-112.0, 33.4), (-111.6, 35.2)]),                  # I-17\n",
    "        LineString([(-112.0, 33.4), (-110.5, 33.8), (-109.0, 34.2)])   # US-60\n",
    "    ]\n",
    "}, crs='EPSG:4326')\n",
    "\n",
    "print(\"‚úÖ Sample spatial data created!\")\n",
    "print(f\"üìç Points: {len(sample_points)} features\")\n",
    "print(f\"üèõÔ∏è Polygons: {len(sample_polygons)} features\")\n",
    "print(f\"üõ£Ô∏è Lines: {len(sample_lines)} features\")\n",
    "\n",
    "# Quick visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "sample_points.plot(ax=axes[0], color='red', markersize=100, alpha=0.7)\n",
    "axes[0].set_title('Sample Points (Cities)')\n",
    "axes[0].set_xlabel('Longitude')\n",
    "axes[0].set_ylabel('Latitude')\n",
    "\n",
    "sample_polygons.plot(ax=axes[1], color='blue', alpha=0.5, edgecolor='black')\n",
    "axes[1].set_title('Sample Polygons (Counties)')\n",
    "axes[1].set_xlabel('Longitude')\n",
    "\n",
    "sample_lines.plot(ax=axes[2], color='green', linewidth=3)\n",
    "axes[2].set_title('Sample Lines (Highways)')\n",
    "axes[2].set_xlabel('Longitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-functions-section",
   "metadata": {},
   "source": [
    "## üîç Test Your Spatial Data Loading Functions\n",
    "\n",
    "Now let's test the functions you've implemented. If you haven't implemented them yet, these cells will help you understand what each function should do!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explore-properties-header",
   "metadata": {},
   "source": [
    "### 1. üìä Explore Spatial Properties\n",
    "\n",
    "Let's test the `explore_spatial_properties()` function with our sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-explore-properties",
   "metadata": {},
   "outputs": [],
   "source": [
    "if functions_available:\n",
    "    # Test with point data\n",
    "    print(\"üîç Exploring point data properties...\")\n",
    "    point_properties = explore_spatial_properties(sample_points)\n",
    "    \n",
    "    print(f\"\\nüìä Point Data Analysis:\")\n",
    "    print(f\"   Features: {point_properties['feature_count']}\")\n",
    "    print(f\"   Primary geometry: {point_properties['primary_geometry_type']}\")\n",
    "    print(f\"   CRS: {point_properties['crs_type']} ({point_properties['epsg_code']})\")\n",
    "    print(f\"   Valid geometries: {point_properties['valid_geometries']}/{point_properties['feature_count']}\")\n",
    "    \n",
    "    if 'spatial_extent' in point_properties and point_properties['spatial_extent']:\n",
    "        extent = point_properties['spatial_extent']\n",
    "        print(f\"   Extent: ({extent['min_x']:.3f}, {extent['min_y']:.3f}) to ({extent['max_x']:.3f}, {extent['max_y']:.3f})\")\n",
    "    \n",
    "    # Test with polygon data\n",
    "    print(\"\\nüîç Exploring polygon data properties...\")\n",
    "    polygon_properties = explore_spatial_properties(sample_polygons)\n",
    "    \n",
    "    print(f\"\\nüèõÔ∏è Polygon Data Analysis:\")\n",
    "    print(f\"   Features: {polygon_properties['feature_count']}\")\n",
    "    print(f\"   Primary geometry: {polygon_properties['primary_geometry_type']}\")\n",
    "    print(f\"   Extent width: {polygon_properties['extent_width']:.3f}¬∞\")\n",
    "    print(f\"   Extent height: {polygon_properties['extent_height']:.3f}¬∞\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Functions not available. Here's what explore_spatial_properties() should return:\")\n",
    "    print(\"\"\"Expected output structure:\n",
    "    {\n",
    "        'feature_count': 5,\n",
    "        'attribute_count': 3,\n",
    "        'primary_geometry_type': 'Point',\n",
    "        'crs_type': 'geographic',\n",
    "        'epsg_code': 4326,\n",
    "        'valid_geometries': 5,\n",
    "        'spatial_extent': {'min_x': -114.627, 'max_x': -110.926, ...},\n",
    "        'centroid': {'x': -112.35, 'y': 33.58},\n",
    "        ...\n",
    "    }\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validate-data-header",
   "metadata": {},
   "source": [
    "### 2. ‚úÖ Validate Spatial Data\n",
    "\n",
    "Let's test the `validate_spatial_data()` function. First, we'll create some problematic data to test with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-problematic-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial data with various issues for testing\n",
    "problematic_data = gpd.GeoDataFrame({\n",
    "    'id': [1, 2, 3, 4, 5],\n",
    "    'name': ['Good Point', 'Null Geometry', 'Invalid Polygon', 'Empty Geometry', 'Duplicate'],\n",
    "    'value': [100, 200, 300, 400, 100],\n",
    "    'geometry': [\n",
    "        Point(0, 0),                                           # Valid point\n",
    "        None,                                                  # Null geometry\n",
    "        Polygon([(0,0), (2,2), (2,0), (0,2), (0,0)]),        # Self-intersecting polygon\n",
    "        Point().buffer(0),                                     # Empty geometry\n",
    "        Point(0, 0)                                           # Duplicate geometry\n",
    "    ]\n",
    "}) \n",
    "\n",
    "# Don't set CRS to test missing CRS detection\n",
    "print(\"üîß Created problematic spatial data for testing:\")\n",
    "print(f\"   - {len(problematic_data)} features\")\n",
    "print(f\"   - Missing CRS: {problematic_data.crs is None}\")\n",
    "print(f\"   - Null geometries: {problematic_data.geometry.isna().sum()}\")\n",
    "print(f\"   - Empty geometries: {problematic_data.geometry.is_empty.sum()}\")\n",
    "print(f\"   - Invalid geometries: {(~problematic_data.geometry.is_valid).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-validate-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "if functions_available:\n",
    "    print(\"üîç Testing data validation...\")\n",
    "    \n",
    "    # Test validation without fixing\n",
    "    validated_gdf, report = validate_spatial_data(problematic_data, fix_issues=False)\n",
    "    \n",
    "    print(f\"\\nüìã Validation Report (fix_issues=False):\")\n",
    "    print(f\"   Original features: {report['original_feature_count']}\")\n",
    "    print(f\"   Final features: {report['final_feature_count']}\")\n",
    "    print(f\"   Issues found: {len(report['issues_found'])}\")\n",
    "    \n",
    "    for issue in report['issues_found']:\n",
    "        print(f\"     - {issue}\")\n",
    "    \n",
    "    # Test validation with fixing\n",
    "    print(\"\\nüîß Testing validation with automatic fixing...\")\n",
    "    fixed_gdf, fix_report = validate_spatial_data(problematic_data, fix_issues=True)\n",
    "    \n",
    "    print(f\"\\nüõ†Ô∏è Validation Report (fix_issues=True):\")\n",
    "    print(f\"   Original features: {fix_report['original_feature_count']}\")\n",
    "    print(f\"   Final features: {fix_report['final_feature_count']}\")\n",
    "    print(f\"   Fixes applied: {len(fix_report['fixes_applied'])}\")\n",
    "    \n",
    "    for fix in fix_report['fixes_applied']:\n",
    "        print(f\"     ‚úÖ {fix}\")\n",
    "        \n",
    "    print(f\"\\n‚úÖ Validation successful: {fix_report['validation_successful']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Functions not available. Validation should detect and optionally fix:\")\n",
    "    print(\"   - Missing coordinate reference systems\")\n",
    "    print(\"   - Invalid geometries (self-intersecting, etc.)\")\n",
    "    print(\"   - Null/empty geometries\")\n",
    "    print(\"   - Duplicate geometries\")\n",
    "    print(\"   - Coordinate values outside reasonable ranges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standardize-crs-header",
   "metadata": {},
   "source": [
    "### 3. üåê Standardize Coordinate Reference Systems\n",
    "\n",
    "Let's test the `standardize_crs()` function with different coordinate transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-crs-standardization",
   "metadata": {},
   "outputs": [],
   "source": [
    "if functions_available:\n",
    "    print(\"üåê Testing CRS standardization...\")\n",
    "    \n",
    "    # Test transformation to Web Mercator (common for web mapping)\n",
    "    print(\"\\nüìç Transforming to Web Mercator (EPSG:3857)...\")\n",
    "    transformed_gdf, transform_report = standardize_crs(sample_points, target_crs='EPSG:3857')\n",
    "    \n",
    "    print(f\"   Original CRS: {transform_report['original_crs']}\")\n",
    "    print(f\"   Target CRS: {transform_report['target_crs']}\")\n",
    "    print(f\"   Transformation applied: {transform_report['transformation_applied']}\")\n",
    "    \n",
    "    if transform_report['transformation_applied']:\n",
    "        print(f\"   Original bounds: {sample_points.total_bounds}\")\n",
    "        print(f\"   Transformed bounds: {transformed_gdf.total_bounds}\")\n",
    "        \n",
    "        # Show coordinate differences\n",
    "        print(f\"\\nüìä Coordinate comparison:\")\n",
    "        for i, (idx, row) in enumerate(sample_points.head(3).iterrows()):\n",
    "            original_coords = (row.geometry.x, row.geometry.y)\n",
    "            transformed_coords = (transformed_gdf.iloc[i].geometry.x, transformed_gdf.iloc[i].geometry.y)\n",
    "            print(f\"   {row['name']}:\")\n",
    "            print(f\"     WGS84: ({original_coords[0]:.3f}, {original_coords[1]:.3f})\")\n",
    "            print(f\"     Web Mercator: ({transformed_coords[0]:.0f}, {transformed_coords[1]:.0f})\")\n",
    "    \n",
    "    # Test auto-selection\n",
    "    print(\"\\nü§ñ Testing automatic CRS selection...\")\n",
    "    auto_gdf, auto_report = standardize_crs(sample_points, auto_select=True)\n",
    "    \n",
    "    print(f\"   Auto-selection used: {auto_report['auto_selection_used']}\")\n",
    "    if auto_report['auto_selection_used']:\n",
    "        print(f\"   Selected CRS: {auto_report['target_crs']}\")\n",
    "        print(f\"   Transformation applied: {auto_report['transformation_applied']}\")\n",
    "    \n",
    "    # Show any warnings\n",
    "    if 'warnings' in transform_report and transform_report['warnings']:\n",
    "        print(f\"\\n‚ö†Ô∏è Warnings:\")\n",
    "        for warning in transform_report['warnings']:\n",
    "            print(f\"   - {warning}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Functions not available. CRS standardization should:\")\n",
    "    print(\"   - Transform coordinates between different reference systems\")\n",
    "    print(\"   - Handle missing CRS by assuming WGS84 for reasonable coordinates\")\n",
    "    print(\"   - Auto-select appropriate CRS based on data location\")\n",
    "    print(\"   - Report coordinate shifts and transformation statistics\")\n",
    "    print(\"   - Handle edge cases like empty datasets gracefully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "file-operations-header",
   "metadata": {},
   "source": [
    "### 4. üìÅ Test File Loading Operations\n",
    "\n",
    "Let's test the `load_spatial_dataset()` function by creating and loading different file formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-file-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary files for testing\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    temp_path = Path(temp_dir)\n",
    "    \n",
    "    # Save sample data in different formats\n",
    "    geojson_file = temp_path / \"test_points.geojson\"\n",
    "    csv_file = temp_path / \"test_coords.csv\"\n",
    "    \n",
    "    # Save as GeoJSON\n",
    "    sample_points.to_file(geojson_file, driver='GeoJSON')\n",
    "    print(f\"‚úÖ Saved GeoJSON file: {geojson_file.name}\")\n",
    "    \n",
    "    # Create CSV with coordinate columns\n",
    "    csv_data = pd.DataFrame({\n",
    "        'name': ['Location A', 'Location B', 'Location C'],\n",
    "        'longitude': [-110.0, -111.0, -112.0],\n",
    "        'latitude': [32.0, 33.0, 34.0],\n",
    "        'category': ['urban', 'rural', 'suburban'],\n",
    "        'value': [100, 200, 300]\n",
    "    })\n",
    "    csv_data.to_csv(csv_file, index=False)\n",
    "    print(f\"‚úÖ Saved CSV file: {csv_file.name}\")\n",
    "    \n",
    "    if functions_available:\n",
    "        # Test loading GeoJSON\n",
    "        print(\"\\nüìÇ Testing GeoJSON loading...\")\n",
    "        try:\n",
    "            loaded_geojson = load_spatial_dataset(geojson_file)\n",
    "            print(f\"   ‚úÖ Loaded {len(loaded_geojson)} features from GeoJSON\")\n",
    "            print(f\"   üìç CRS: {loaded_geojson.crs}\")\n",
    "            print(f\"   üìä Columns: {list(loaded_geojson.columns)}\")\n",
    "            print(f\"   üó∫Ô∏è Geometry types: {loaded_geojson.geometry.geom_type.value_counts().to_dict()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå GeoJSON loading failed: {e}\")\n",
    "        \n",
    "        # Test loading CSV with coordinates\n",
    "        print(\"\\nüìä Testing CSV coordinate loading...\")\n",
    "        try:\n",
    "            loaded_csv = load_spatial_dataset(csv_file)\n",
    "            print(f\"   ‚úÖ Loaded {len(loaded_csv)} features from CSV\")\n",
    "            print(f\"   üìç CRS: {loaded_csv.crs}\")\n",
    "            print(f\"   üìä Columns: {list(loaded_csv.columns)}\")\n",
    "            print(f\"   üó∫Ô∏è Geometry types: {loaded_csv.geometry.geom_type.value_counts().to_dict()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå CSV loading failed: {e}\")\n",
    "        \n",
    "        # Test error handling\n",
    "        print(\"\\nüö® Testing error handling...\")\n",
    "        try:\n",
    "            missing_file = temp_path / \"nonexistent.shp\"\n",
    "            load_spatial_dataset(missing_file)\n",
    "            print(\"   ‚ùå Should have raised FileNotFoundError!\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"   ‚úÖ Correctly raised FileNotFoundError for missing file\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Unexpected error: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Functions not available. File loading should:\")\n",
    "        print(\"   - Detect file format from extension\")\n",
    "        print(\"   - Handle GeoJSON, Shapefile, GeoPackage formats\")\n",
    "        print(\"   - Create geometries from CSV coordinate columns\")\n",
    "        print(\"   - Raise appropriate errors for missing files\")\n",
    "        print(\"   - Handle encoding issues gracefully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-section",
   "metadata": {},
   "source": [
    "## üé® Visualization Examples\n",
    "\n",
    "Let's create some visualizations to better understand our spatial data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-visualizations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive visualization of all our sample data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Points with population size\n",
    "sample_points.plot(ax=axes[0,0], \n",
    "                   column='population', \n",
    "                   markersize=sample_points['population']/10000,  # Scale by population\n",
    "                   cmap='Reds', \n",
    "                   alpha=0.7,\n",
    "                   legend=True)\n",
    "axes[0,0].set_title('Arizona Cities by Population')\n",
    "axes[0,0].set_xlabel('Longitude')\n",
    "axes[0,0].set_ylabel('Latitude'
