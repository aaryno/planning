{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function 5: Save Processed Data 💾\n",
    "\n",
    "**Welcome to data saving with pandas!**\n",
    "\n",
    "In this notebook, you'll learn how to build the `save_processed_data()` function step by step. This is like saving your work in Excel - taking your processed DataFrame and writing it to a CSV file that you can use in other programs like QGIS.\n",
    "\n",
    "## 🎯 What This Function Does\n",
    "- Saves a pandas DataFrame to a CSV file with proper formatting\n",
    "- Validates that the data was saved correctly\n",
    "- Reports file size and location information\n",
    "- Handles errors gracefully (like permission issues or invalid paths)\n",
    "- Provides confirmation that the data is ready for use\n",
    "\n",
    "## 🔧 Function Signature\n",
    "```python\n",
    "def save_processed_data(df, output_file):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The processed data to save\n",
    "        output_file (str): Path where to save the CSV file (e.g., 'output/processed_data.csv')\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if saving was successful, False otherwise\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Step 1: Import Libraries and Prepare Sample Data\n",
    "\n",
    "First, let's set up our environment and create some sample processed data to save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"✅ Pandas version: {pd.__version__}\")\n",
    "print(\"💾 Ready to save data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample processed data (simulating the result of our previous functions)\n",
    "print(\"🔬 CREATING SAMPLE PROCESSED DATA:\\n\")\n",
    "\n",
    "# Load and process some real data first\n",
    "readings_df = pd.read_csv('../data/temperature_readings.csv')\n",
    "stations_df = pd.read_csv('../data/weather_stations.csv')\n",
    "\n",
    "# Create a processed dataset (joined and filtered)\n",
    "processed_df = pd.merge(readings_df, stations_df, on='station_id', how='left')\n",
    "processed_df = processed_df[(processed_df['temperature_c'] >= 15) & \n",
    "                           (processed_df['temperature_c'] <= 30) & \n",
    "                           (processed_df['data_quality'] == 'good')]\n",
    "\n",
    "print(f\"📊 Sample processed data created:\")\n",
    "print(f\"   Shape: {processed_df.shape}\")\n",
    "print(f\"   Columns: {list(processed_df.columns)}\")\n",
    "\n",
    "print(\"\\n🔍 First 3 rows of processed data:\")\n",
    "display(processed_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📁 Step 2: Understanding File Paths and Output Directories\n",
    "\n",
    "Before saving data, we need to understand where to put our files and how to create directories if they don't exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the current directory structure\n",
    "print(\"📂 CURRENT DIRECTORY STRUCTURE:\\n\")\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Directory contents:\")\n",
    "\n",
    "# Look at parent directory (go up from notebooks)\n",
    "parent_dir = Path('../')\n",
    "for item in parent_dir.iterdir():\n",
    "    if item.is_file():\n",
    "        print(f\"   📄 {item.name}\")\n",
    "    else:\n",
    "        print(f\"   📁 {item.name}/\")\n",
    "\n",
    "# Check if output directory exists\n",
    "output_dir = Path('../output')\n",
    "print(f\"\\n📁 Output directory status:\")\n",
    "if output_dir.exists():\n",
    "    print(f\"   ✅ '{output_dir}' exists\")\n",
    "    print(f\"   Contents: {list(output_dir.iterdir()) if output_dir.is_dir() else 'Not a directory'}\")\nelse:\n",
    "    print(f\"   ⚠️  '{output_dir}' does not exist - we'll need to create it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💾 Step 3: Basic CSV Saving\n",
    "\n",
    "Let's start with the simplest way to save a DataFrame to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic CSV saving\n",
    "print(\"💾 BASIC CSV SAVING:\\n\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = Path('../output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "print(f\"📁 Ensured output directory exists: {output_dir}\")\n",
    "\n",
    "# Save a simple CSV\n",
    "basic_output_file = output_dir / 'basic_example.csv'\n",
    "\n",
    "try:\n",
    "    processed_df.to_csv(basic_output_file, index=False)\n",
    "    print(f\"✅ Successfully saved to: {basic_output_file}\")\n",
    "    \n",
    "    # Check that the file was created\n",
    "    if basic_output_file.exists():\n",
    "        file_size = basic_output_file.stat().st_size\n",
    "        print(f\"📊 File size: {file_size:,} bytes ({file_size/1024:.1f} KB)\")\n",
    "        \n",
    "        # Count lines in the file\n",
    "        with open(basic_output_file, 'r') as f:\n",
    "            line_count = sum(1 for line in f)\n",
    "        print(f\"📄 Lines in file: {line_count} (including header)\")\n",
    "        print(f\"📊 Data rows: {line_count - 1}\")\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"❌ Error saving file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Step 4: Validating Saved Data\n",
    "\n",
    "After saving, we should verify that the data was saved correctly by reading it back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate saved data by reading it back\n",
    "print(\"🔍 VALIDATING SAVED DATA:\\n\")\n",
    "\n",
    "try:\n",
    "    # Read the file back\n",
    "    reloaded_df = pd.read_csv(basic_output_file)\n",
    "    \n",
    "    print(f\"📊 VALIDATION RESULTS:\")\n",
    "    print(f\"   Original shape: {processed_df.shape}\")\n",
    "    print(f\"   Reloaded shape: {reloaded_df.shape}\")\n",
    "    print(f\"   ✅ Shapes match: {processed_df.shape == reloaded_df.shape}\")\n",
    "    \n",
    "    # Check columns\n",
    "    original_cols = set(processed_df.columns)\n",
    "    reloaded_cols = set(reloaded_df.columns)\n",
    "    print(f\"   ✅ Columns match: {original_cols == reloaded_cols}\")\n",
    "    \n",
    "    # Check a few data points\n",
    "    print(f\"\\n🔍 Data integrity check:\")\n",
    "    print(f\"   First temperature value - Original: {processed_df['temperature_c'].iloc[0]}, Reloaded: {reloaded_df['temperature_c'].iloc[0]}\")\n",
    "    print(f\"   First station ID - Original: {processed_df['station_id'].iloc[0]}, Reloaded: {reloaded_df['station_id'].iloc[0]}\")\n",
    "    \n",
    "    print(f\"\\n✅ File validation successful!\")\n",
    "    \nexcept Exception as e:\n",
    "    print(f\"❌ Error validating file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎨 Step 5: CSV Formatting Options\n",
    "\n",
    "pandas offers many options for how to format your CSV files. Let's explore the most useful ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore different CSV formatting options\n",
    "print(\"🎨 CSV FORMATTING OPTIONS:\\n\")\n",
    "\n",
    "# Option 1: Default (what we've been using)\n",
    "default_file = output_dir / 'format_default.csv'\n",
    "processed_df.head(3).to_csv(default_file, index=False)\n",
    "print(\"📄 Default format saved\")\n",
    "\n",
    "# Show the first few lines of the default format\n",
    "with open(default_file, 'r') as f:\n",
    "    print(\"   First 3 lines:\")\n",
    "    for i, line in enumerate(f):\n",
    "        if i < 3:\n",
    "            print(f\"   {i+1}: {line.strip()}\")\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Rounded numbers for readability\n",
    "print(\"\\n🔢 FORMATTING WITH ROUNDED NUMBERS:\\n\")\n",
    "\n",
    "# Create a copy with rounded values\n",
    "rounded_df = processed_df.copy()\n",
    "numeric_columns = ['temperature_c', 'humidity_percent', 'latitude', 'longitude', 'elevation_m']\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if col in rounded_df.columns:\n",
    "        rounded_df[col] = rounded_df[col].round(2)\n",
    "\n",
    "rounded_file = output_dir / 'format_rounded.csv'\n",
    "rounded_df.head(3).to_csv(rounded_file, index=False)\n",
    "print(\"📄 Rounded format saved\")\n",
    "\n",
    "# Compare the first numeric row\n",
    "print(\"\\n📊 Comparison of first data row:\")\n",
    "print(\"   Original temperature:\", processed_df['temperature_c'].iloc[0])\n",
    "print(\"   Rounded temperature:\", rounded_df['temperature_c'].iloc[0])\n",
    "if 'latitude' in rounded_df.columns and pd.notna(rounded_df['latitude'].iloc[0]):\n",
    "    print(\"   Original latitude:\", processed_df['latitude'].iloc[0])\n",
    "    print(\"   Rounded latitude:\", rounded_df['latitude'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Custom delimiter (for special cases)\n",
    "print(\"\\n📝 CUSTOM DELIMITER EXAMPLE:\\n\")\n",
    "\n",
    "# Sometimes you need semicolon or tab separation\n",
    "semicolon_file = output_dir / 'format_semicolon.csv'\n",
    "processed_df.head(3).to_csv(semicolon_file, index=False, sep=';')\n",
    "print(\"📄 Semicolon-separated format saved\")\n",
    "\n",
    "with open(semicolon_file, 'r') as f:\n",
    "    print(\"   First data line:\")\n",
    "    lines = f.readlines()\n",
    "    if len(lines) > 1:\n",
    "        print(f\"   {lines[1].strip()}\")\n",
    "        \n",
    "# Tab-separated (TSV)\n",
    "tab_file = output_dir / 'format_tab.tsv'\n",
    "processed_df.head(3).to_csv(tab_file, index=False, sep='\\t')\n",
    "print(\"\\n📄 Tab-separated format saved as .tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚠️ Step 6: Error Handling\n",
    "\n",
    "Real-world file saving can fail for many reasons. Let's practice handling common errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common error scenarios\n",
    "print(\"⚠️ TESTING ERROR HANDLING:\\n\")\n",
    "\n",
    "# Error 1: Invalid directory path\n",
    "print(\"🧪 Test 1: Invalid directory path\")\n",
    "invalid_path = '/nonexistent/directory/file.csv'\n",
    "try:\n",
    "    processed_df.head(2).to_csv(invalid_path, index=False)\n",
    "    print(\"   ✅ Unexpected success\")\nexcept Exception as e:\n",
    "    print(f\"   ❌ Expected error: {type(e).__name__}: {e}\")\n",
    "\n",
    "# Error 2: Protected file (simulate by creating a directory with the same name)\n",
    "print(\"\\n🧪 Test 2: File path conflicts\")\n",
    "conflict_path = output_dir / 'test_directory_conflict'\n",
    "try:\n",
    "    # Create a directory with the name we want for our file\n",
    "    conflict_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Now try to save a file with that name\n",
    "    processed_df.head(2).to_csv(conflict_path, index=False)\n",
    "    print(\"   ✅ Unexpected success\")\nexcept Exception as e:\n",
    "    print(f\"   ❌ Expected error: {type(e).__name__}: {e}\")\n",
    "finally:\n",
    "    # Clean up\n",
    "    if conflict_path.exists() and conflict_path.is_dir():\n",
    "        conflict_path.rmdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error 3: Empty DataFrame\n",
    "print(\"\\n🧪 Test 3: Empty DataFrame\")\n",
    "empty_df = pd.DataFrame()\n",
    "empty_file = output_dir / 'empty_test.csv'\n",
    "\n",
    "try:\n",
    "    empty_df.to_csv(empty_file, index=False)\n",
    "    print(\"   ✅ Empty DataFrame saved successfully\")\n",
    "    \n",
    "    # Check what was actually saved\n",
    "    if empty_file.exists():\n",
    "        with open(empty_file, 'r') as f:\n",
    "            content = f.read()\n",
    "        print(f\"   📄 File content: '{content}' (length: {len(content)})\")\n",
    "        \n",
    "        # Verify by reading back\n",
    "        reloaded_empty = pd.read_csv(empty_file)\n",
    "        print(f\"   📊 Reloaded shape: {reloaded_empty.shape}\")\n",
    "        \nexcept Exception as e:\n",
    "    print(f\"   ❌ Error with empty DataFrame: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📏 Step 7: File Size and Performance Considerations\n",
    "\n",
    "Let's understand how file size relates to data size and explore performance considerations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze file sizes for different data amounts\n",
    "print(\"📏 FILE SIZE ANALYSIS:\\n\")\n",
    "\n",
    "# Test with different amounts of data\n",
    "data_sizes = [1, 5, 10, len(processed_df)]\n",
    "size_results = []\n",
    "\n",
    "for size in data_sizes:\n",
    "    if size <= len(processed_df):\n",
    "        test_df = processed_df.head(size)\n",
    "        test_file = output_dir / f'size_test_{size}_rows.csv'\n",
    "        \n",
    "        try:\n",
    "            # Time the saving operation\n",
    "            import time\n",
    "            start_time = time.time()\n",
    "            test_df.to_csv(test_file, index=False)\n",
    "            save_time = time.time() - start_time\n",
    "            \n",
    "            # Get file size\n",
    "            file_size = test_file.stat().st_size\n",
    "            \n",
    "            size_results.append({\n",
    "                'rows': size,\n",
    "                'columns': len(test_df.columns),\n",
    "                'file_size_bytes': file_size,\n",
    "                'file_size_kb': file_size / 1024,\n",
    "                'save_time_ms': save_time * 1000\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   Error with {size} rows: {e}\")\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(size_results)\n",
    "print(\"📊 File size and performance results:\")\n",
    "display(results_df)\n",
    "\n",
    "# Calculate efficiency metrics\n",
    "if len(results_df) > 1:\n",
    "    print(\"\\n📈 Efficiency insights:\")\n",
    "    print(f\"   Bytes per row: {results_df['file_size_bytes'].iloc[-1] / results_df['rows'].iloc[-1]:.1f}\")\n",
    "    print(f\"   Milliseconds per row: {results_df['save_time_ms'].iloc[-1] / results_df['rows'].iloc[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏗️ Step 8: Building the Complete Function\n",
    "\n",
    "Now let's put everything together into the complete `save_processed_data()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_data(df, output_file):\n",
    "    \"\"\"\n",
    "    Save a processed pandas DataFrame to a CSV file with validation.\n",
    "    \n",
    "    This function demonstrates proper data saving practices including\n",
    "    directory creation, error handling, and result validation.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): The processed data to save\n",
    "        output_file (str): Path where to save the CSV file\n",
    "                          (e.g., 'output/processed_data.csv')\n",
    "                          \n",
    "    Returns:\n",
    "        bool: True if saving was successful, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"SAVING PROCESSED DATA\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Input validation\n",
    "    if df is None:\n",
    "        print(\"❌ ERROR: DataFrame is None\")\n",
    "        return False\n",
    "        \n",
    "    if df.empty:\n",
    "        print(\"⚠️  WARNING: DataFrame is empty\")\n",
    "        print(\"   Proceeding to save empty file...\")\n",
    "    \n",
    "    if not output_file or not isinstance(output_file, str):\n",
    "        print(\"❌ ERROR: Invalid output file path\")\n",
    "        return False\n",
    "    \n",
    "    # Convert to Path object for easier manipulation\n",
    "    output_path = Path(output_file)\n",
    "    \n",
    "    print(f\"📊 DATA TO SAVE:\")\n",
    "    print(f\"   Shape: {df.shape}\")\n",
    "    print(f\"   Columns: {len(df.columns)}\")\n",
    "    if not df.empty:\n",
    "        memory_usage = df.memory_usage(deep=True).sum()\n",
    "        print(f\"   Memory usage: {memory_usage:,} bytes ({memory_usage/1024:.1f} KB)\")\n",
    "    \n",
    "    print(f\"\\n📁 OUTPUT LOCATION:\")\n",
    "    print(f\"   File path: {output_path}\")\n",
    "    print(f\"   Directory: {output_path.parent}\")\n",
    "    print(f\"   Filename: {output_path.name}\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    try:\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"   ✅ Output directory ready\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Cannot create output directory: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Save the data\n",
    "    print(f\"\\n💾 SAVING DATA...\")\n",
    "    try:\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Save with optimized settings\n",
    "        df.to_csv(\n",
    "            output_path,\n",
    "            index=False,           # Don't save row indices\n",
    "            float_format='%.3f',   # Round floats to 3 decimal places\n",
    "            na_rep='',             # Empty string for missing values\n",
    "            date_format='%Y-%m-%d' # Standard date format\n",
    "        )\n",
    "        \n",
    "        save_time = time.time() - start_time\n",
    "        print(f\"   ✅ Data saved successfully in {save_time:.3f} seconds\")\n",
    "        \n",
    "    except PermissionError:\n",
    "        print(f\"   ❌ Permission denied: Cannot write to {output_path}\")\n",
    "        print(f\"   💡 Try saving to a different location or check file permissions\")\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        print(f\"   ❌ Directory not found: {output_path.parent}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Unexpected error saving file: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Validate the saved file\n",
    "    print(f\"\\n🔍 VALIDATING SAVED FILE...\")\n",
    "    \n",
    "    if not output_path.exists():\n",
    "        print(f\"   ❌ File was not created: {output_path}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Check file size\n",
    "        file_size = output_path.stat().st_size\n",
    "        print(f\"   📏 File size: {file_size:,} bytes ({file_size/1024:.1f} KB)\")\n",
    "        \n",
    "        # Verify by reading back\n",
    "        verification_df = pd.read_csv(output_path)\n",
    "        \n",
    "        print(f\"   ✅ File validation successful:\")\n",
    "        print(f\"      Original shape: {df.shape}\")\n",
    "        print(f\"      Saved shape: {verification_df.shape}\")\n",
    "        print(f\"      Shape match: {df.shape == verification_df.shape}\")\n",
    "        \n",
    "        # Check column preservation\n",
    "        original_columns = set(df.columns)\n",
    "        saved_columns = set(verification_df.columns)\n",
    "        columns_match = original_columns == saved_columns\n",
    "        print(f\"      Columns match: {columns_match}\")\n",
    "        \n",
    "        if not columns_match:\n",
    "            missing_cols = original_columns - saved_columns\n",
    "            extra_cols = saved_columns - original_columns\n",
    "            if missing_cols:\n",
    "                print(f\"      Missing columns: {list(missing_cols)}\")\n",
    "            if extra_cols:\n",
    "                print(f\"      Extra columns: {list(extra_cols)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️  File saved but validation failed: {e}\")\n",
    "        print(f\"   The file may still be usable.\")\n",
    "    \n",
    "    # Success summary\n",
    "    print(f\"\\n🎉 SUCCESS SUMMARY:\")\n",
    "    print(f\"   📁 File location: {output_path.resolve()}\")\n",
    "    print(f\"   📊 Data rows saved: {len(df)}\")\n",
    "    print(f\"   📋 Columns saved: {len(df.columns) if not df.empty else 0}\")\n",
    "    print(f\"   💾 Ready for use in QGIS, Excel, or other GIS software!\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✨ Step 9: Test Your Complete Function\n",
    "\n",
    "Let's test our complete function with different scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Normal operation with processed data\n",
    "print(\"🧪 TEST 1: NORMAL OPERATION WITH PROCESSED DATA\\n\")\n",
    "success1 = save_processed_data(processed_df, '../output/test1_processed_environmental_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Automatic directory creation\n",
    "print
