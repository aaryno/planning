{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ðŸ“ Loading Spatial Data - Mastering Data Input\n",
    "\n",
    "**GIST 604B - Python GeoPandas Introduction**  \n",
    "**Notebook 2: Load Spatial Data from Various Sources**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "- Load spatial data from different file formats (GeoJSON, Shapefile, etc.)\n",
    "- Handle file paths using both strings and Path objects\n",
    "- Troubleshoot common loading errors and encoding issues\n",
    "- Implement robust error handling for spatial data loading\n",
    "- Understand the differences between spatial file formats\n",
    "- **Prepare to implement the `load_spatial_dataset()` function**\n",
    "\n",
    "## ðŸ—‚ï¸ What You'll Practice\n",
    "\n",
    "This notebook directly prepares you to implement the **`load_spatial_dataset()`** function in your assignment. You'll learn:\n",
    "\n",
    "1. **File Format Detection**: How to determine what type of spatial file you're working with\n",
    "2. **Error Handling**: What can go wrong when loading spatial data and how to handle it\n",
    "3. **Path Management**: Working with file paths in a robust way\n",
    "4. **Data Validation**: Ensuring loaded data is actually valid spatial data\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Getting Started\n",
    "\n",
    "Let's start by importing the libraries we'll need and setting up our workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“š Import required libraries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ðŸ”§ Libraries imported successfully!\")\n",
    "print(f\"ðŸ“¦ GeoPandas version: {gpd.__version__}\")\n",
    "print(f\"ðŸ¼ Pandas version: {pd.__version__}\")\n",
    "\n",
    "# Check our data directory\n",
    "data_path = Path('../data')\n",
    "print(f\"\\nðŸ“ Data directory exists: {data_path.exists()}\")\n",
    "if data_path.exists():\n",
    "    subdirs = [d.name for d in data_path.iterdir() if d.is_dir()]\n",
    "    print(f\"ðŸ“‚ Available datasets: {subdirs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic_loading",
   "metadata": {},
   "source": [
    "## ðŸ“– Basic Spatial Data Loading\n",
    "\n",
    "The most fundamental operation in spatial analysis is loading data. GeoPandas makes this remarkably simple with the `gpd.read_file()` function.\n",
    "\n",
    "### ðŸŽ¯ The Universal Loader\n",
    "\n",
    "Unlike regular pandas which has separate functions for different formats (`read_csv()`, `read_json()`, etc.), GeoPandas uses **one function for all spatial formats**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic_load_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŒ Load spatial data - it's this simple!\n",
    "\n",
    "print(\"ðŸ“ Loading different spatial formats with the same function:\\n\")\n",
    "\n",
    "# Method 1: Load GeoJSON\n",
    "cities_geojson = gpd.read_file('../data/cities/sample_cities.geojson')\n",
    "print(f\"ðŸ“„ GeoJSON: Loaded {len(cities_geojson)} cities\")\n",
    "print(f\"   Columns: {list(cities_geojson.columns)}\")\n",
    "\n",
    "# Method 2: Load Shapefile\n",
    "cities_shapefile = gpd.read_file('../data/cities/world_cities.shp')\n",
    "print(f\"\\nðŸ“„ Shapefile: Loaded {len(cities_shapefile)} cities\")\n",
    "print(f\"   Columns: {list(cities_shapefile.columns)}\")\n",
    "\n",
    "print(\"\\nâœ¨ Same function, different formats - GeoPandas handles the details!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "path_handling",
   "metadata": {},
   "source": [
    "## ðŸ›£ï¸ Working with File Paths\n",
    "\n",
    "Professional code needs to handle file paths robustly. Let's explore different ways to specify file paths and why the `pathlib.Path` approach is preferred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "path_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ›£ï¸ Different ways to handle file paths\n",
    "\n",
    "print(\"ðŸ”§ Path Handling Methods:\\n\")\n",
    "\n",
    "# Method 1: String paths (traditional)\n",
    "file_path_string = '../data/cities/sample_cities.geojson'\n",
    "cities_string = gpd.read_file(file_path_string)\n",
    "print(f\"ðŸ“ String path: '{file_path_string}'\")\n",
    "print(f\"   Result: {len(cities_string)} cities loaded\")\n",
    "\n",
    "# Method 2: Path objects (modern, recommended)\n",
    "file_path_object = Path('../data/cities/sample_cities.geojson')\n",
    "cities_path = gpd.read_file(file_path_object)\n",
    "print(f\"\\nðŸ—‚ï¸ Path object: {file_path_object}\")\n",
    "print(f\"   Result: {len(cities_path)} cities loaded\")\n",
    "\n",
    "# Path object advantages\n",
    "print(f\"\\nðŸ’¡ Path Object Advantages:\")\n",
    "print(f\"   ðŸ“ Absolute path: {file_path_object.absolute()}\")\n",
    "print(f\"   ðŸ“„ File name: {file_path_object.name}\")\n",
    "print(f\"   ðŸ“‚ Parent directory: {file_path_object.parent}\")\n",
    "print(f\"   ðŸ” File exists: {file_path_object.exists()}\")\n",
    "print(f\"   ðŸ“Š File size: {file_path_object.stat().st_size} bytes\")\n",
    "\n",
    "# Both approaches work identically\n",
    "print(f\"\\nâœ… Both methods load identical data: {cities_string.equals(cities_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "format_comparison",
   "metadata": {},
   "source": [
    "## ðŸ” Understanding Spatial File Formats\n",
    "\n",
    "Different spatial formats have different characteristics. Let's explore the most common ones and understand when to use each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "format_comparison_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ—‚ï¸ Comparing different spatial file formats\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"ðŸ“Š Spatial File Format Comparison:\\n\")\n",
    "\n",
    "# Load the same data in different formats\n",
    "formats = {\n",
    "    'GeoJSON': '../data/cities/world_cities.geojson',\n",
    "    'Shapefile': '../data/cities/world_cities.shp'\n",
    "}\n",
    "\n",
    "for format_name, file_path in formats.items():\n",
    "    if Path(file_path).exists():\n",
    "        # Load the data\n",
    "        gdf = gpd.read_file(file_path)\n",
    "        \n",
    "        # File size analysis\n",
    "        if format_name == 'Shapefile':\n",
    "            # Shapefile is multiple files\n",
    "            shp_dir = Path(file_path).parent\n",
    "            shp_files = list(shp_dir.glob('world_cities.*'))\n",
    "            total_size = sum(f.stat().st_size for f in shp_files)\n",
    "            file_count = len(shp_files)\n",
    "        else:\n",
    "            # Single file formats\n",
    "            total_size = Path(file_path).stat().st_size\n",
    "            file_count = 1\n",
    "        \n",
    "        print(f\"ðŸ“„ {format_name}:\")\n",
    "        print(f\"   ðŸ’¾ Size: {total_size:,} bytes ({total_size/1024:.1f} KB)\")\n",
    "        print(f\"   ðŸ“ Files: {file_count}\")\n",
    "        print(f\"   ðŸŒ Features: {len(gdf)}\")\n",
    "        print(f\"   ðŸ“Š Columns: {len(gdf.columns)}\")\n",
    "        print(f\"   ðŸ—ºï¸ CRS: {gdf.crs}\")\n",
    "        print()\n",
    "\n",
    "# Format characteristics\n",
    "print(\"ðŸŽ¯ When to Use Each Format:\")\n",
    "print(\"ðŸ“„ GeoJSON:\")\n",
    "print(\"   âœ… Web applications, APIs, JavaScript\")\n",
    "print(\"   âœ… Human-readable text format\")\n",
    "print(\"   âœ… Single file, easy to share\")\n",
    "print(\"   âš ï¸  Larger file sizes\")\n",
    "print(\"\")\n",
    "print(\"ðŸ“„ Shapefile:\")\n",
    "print(\"   âœ… Traditional GIS software\")\n",
    "print(\"   âœ… Widely supported\")\n",
    "print(\"   âœ… Compact file size\")\n",
    "print(\"   âš ï¸  Multiple files to manage\")\n",
    "print(\"   âš ï¸  Column name limitations (10 chars)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error_handling",
   "metadata": {},
   "source": [
    "## âš ï¸ Error Handling and Troubleshooting\n",
    "\n",
    "Real-world spatial data loading often involves problems. Let's explore common errors and how to handle them professionally:\n",
    "\n",
    "### ðŸš¨ Common Loading Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "error_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš¨ Demonstrating common errors and solutions\n",
    "\n",
    "print(\"ðŸ•µï¸ Common Spatial Data Loading Errors:\\n\")\n",
    "\n",
    "# Error 1: File doesn't exist\n",
    "print(\"âŒ Error 1: File Not Found\")\n",
    "try:\n",
    "    missing_file = gpd.read_file('nonexistent_file.geojson')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"   ðŸš¨ Error: {e}\")\n",
    "    print(\"   ðŸ’¡ Solution: Check file path and spelling\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Error 2: Invalid format\n",
    "print(\"âŒ Error 2: Invalid File Format\")\n",
    "# Create a temporary invalid file\n",
    "invalid_file = Path('../data/invalid_spatial_file.txt')\n",
    "invalid_file.write_text(\"This is not spatial data\")\n",
    "\n",
    "try:\n",
    "    invalid_data = gpd.read_file(invalid_file)\n",
    "except Exception as e:\n",
    "    print(f\"   ðŸš¨ Error type: {type(e).__name__}\")\n",
    "    print(f\"   ðŸš¨ Error message: {e}\")\n",
    "    print(\"   ðŸ’¡ Solution: Ensure file contains valid spatial data\")\n",
    "\n",
    "# Clean up\n",
    "invalid_file.unlink()  # Delete the temporary file\n",
    "\n",
    "print()\n",
    "\n",
    "# Error 3: Corrupted data (using our problematic dataset)\n",
    "print(\"âŒ Error 3: Data Quality Issues\")\n",
    "try:\n",
    "    problematic = gpd.read_file('../data/cities/cities_with_issues.geojson')\n",
    "    print(f\"   âš ï¸  File loads but has {problematic.geometry.isna().sum()} missing geometries\")\n",
    "    print(f\"   âš ï¸  File loads but has {(~problematic.geometry.is_valid).sum()} invalid geometries\")\n",
    "    print(\"   ðŸ’¡ Solution: Load successfully, then validate and clean data\")\n",
    "except Exception as e:\n",
    "    print(f\"   ðŸš¨ Error: {e}\")\n",
    "    print(\"   ðŸ’¡ Solution: Check data integrity and format\")\n",
    "\n",
    "print(\"\\nâœ… Key Takeaway: Always handle errors gracefully in production code!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust_loading_function",
   "metadata": {},
   "source": [
    "## ðŸ›¡ï¸ Building a Robust Loading Function\n",
    "\n",
    "Now let's build a professional-grade loading function step by step. This will guide you toward implementing the `load_spatial_dataset()` function in your assignment:\n",
    "\n",
    "### ðŸ”§ Step-by-Step Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust_loader_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ›¡ï¸ Building a robust spatial data loader\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "def demo_load_spatial_dataset(file_path: Union[str, Path], **kwargs) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Demonstration of robust spatial data loading.\n",
    "    This shows you the approach for your assignment implementation.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"ðŸ”„ Loading spatial data from: {file_path}\")\n",
    "    \n",
    "    # Step 1: Convert to Path object\n",
    "    path_obj = Path(file_path)\n",
    "    print(f\"   ðŸ“ Using path object: {path_obj}\")\n",
    "    \n",
    "    # Step 2: Check if file exists\n",
    "    if not path_obj.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path_obj}\")\n",
    "    \n",
    "    print(f\"   âœ… File exists: {path_obj.stat().st_size} bytes\")\n",
    "    \n",
    "    # Step 3: Determine file format\n",
    "    file_extension = path_obj.suffix.lower()\n",
    "    print(f\"   ðŸ—‚ï¸ File format: {file_extension}\")\n",
    "    \n",
    "    # Step 4: Validate supported format\n",
    "    supported_formats = ['.geojson', '.json', '.shp', '.gpkg']\n",
    "    if file_extension not in supported_formats:\n",
    "        raise ValueError(f\"Unsupported format: {file_extension}. Supported: {supported_formats}\")\n",
    "    \n",
    "    # Step 5: Load the data\n",
    "    try:\n",
    "        gdf = gpd.read_file(path_obj, **kwargs)\n",
    "        print(f\"   ðŸ“Š Loaded {len(gdf)} features\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading spatial data: {e}\")\n",
    "    \n",
    "    # Step 6: Basic validation\n",
    "    if not isinstance(gdf, gpd.GeoDataFrame):\n",
    "        raise ValueError(\"Loaded data is not a valid GeoDataFrame\")\n",
    "    \n",
    "    if len(gdf) == 0:\n",
    "        print(\"   âš ï¸ Warning: Dataset is empty\")\n",
    "    \n",
    "    if 'geometry' not in gdf.columns:\n",
    "        raise ValueError(\"No geometry column found in the data\")\n",
    "    \n",
    "    print(f\"   âœ… Validation passed: {len(gdf)} features with geometry\")\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "# Test the function\n",
    "print(\"ðŸ§ª Testing robust loading function:\\n\")\n",
    "\n",
    "# Test 1: Valid GeoJSON\n",
    "try:\n",
    "    cities = demo_load_spatial_dataset('../data/cities/sample_cities.geojson')\n",
    "    print(f\"   Success! Loaded {len(cities)} cities\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\\n\")\n",
    "\n",
    "# Test 2: Valid Shapefile\n",
    "try:\n",
    "    cities_shp = demo_load_spatial_dataset('../data/cities/world_cities.shp')\n",
    "    print(f\"   Success! Loaded {len(cities_shp)} cities\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\\n\")\n",
    "\n",
    "# Test 3: File doesn't exist\n",
    "try:\n",
    "    missing = demo_load_spatial_dataset('missing_file.geojson')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"   Expected error caught: {e}\\n\")\n",
    "\n",
    "print(\"ðŸŽ¯ This demonstrates the approach for your assignment implementation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loading_scenarios",
   "metadata": {},
   "source": [
    "## ðŸŒ Advanced Loading Scenarios\n",
    "\n",
    "Let's explore more advanced loading scenarios you might encounter in real-world projects:\n",
    "\n",
    "### ðŸ“Š Loading with Additional Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced_loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Advanced loading with parameters\n",
    "\n",
    "print(\"ðŸŒ Advanced Loading Scenarios:\\n\")\n",
    "\n",
    "# Scenario 1: Load with encoding specification\n",
    "print(\"ðŸ“ Scenario 1: Explicit encoding\")\n",
    "try:\n",
    "    cities_utf8 = gpd.read_file('../data/cities/sample_cities.geojson', encoding='utf-8')\n",
    "    print(f\"   âœ… Loaded with UTF-8 encoding: {len(cities_utf8)} cities\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ Error: {e}\")\n",
    "\n",
    "# Scenario 2: Load specific columns (for Shapefiles)\n",
    "print(\"\\nðŸ“Š Scenario 2: Load specific columns\")\n",
    "try:\n",
    "    # For demonstration, load only specific columns\n",
    "    cities_subset = gpd.read_file('../data/cities/world_cities.shp', \n",
    "                                 columns=['name', 'country', 'geometry'])\n",
    "    print(f\"   âœ… Loaded subset: {len(cities_subset)} cities with {len(cities_subset.columns)} columns\")\n",
    "    print(f\"   ðŸ“‹ Columns: {list(cities_subset.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ Error: {e}\")\n",
    "\n",
    "# Scenario 3: Load with bounding box filter (if supported)\n",
    "print(\"\\nðŸ—ºï¸ Scenario 3: Spatial filtering (bbox)\")\n",
    "try:\n",
    "    # Define a bounding box (minx, miny, maxx, maxy) for North America\n",
    "    north_america_bbox = [-130, 25, -60, 50]\n",
    "    cities_na = gpd.read_file('../data/cities/world_cities.geojson', \n",
    "                             bbox=north_america_bbox)\n",
    "    print(f\"   âœ… Loaded North America cities: {len(cities_na)} cities\")\n",
    "    if len(cities_na) > 0:\n",
    "        print(f\"   ðŸŒ Sample cities: {', '.join(cities_na['name'].head(3))}\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸ Bbox filtering not supported for this format: {e}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Key Insight: The **kwargs parameter allows flexible loading options!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_validation",
   "metadata": {},
   "source": [
    "## âœ… Data Validation After Loading\n",
    "\n",
    "Loading data is just the first step. Professional spatial analysis always includes data validation:\n",
    "\n",
    "### ðŸ” Essential Validation Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validation_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Post-loading data validation\n",
    "\n",
    "def validate_loaded_data(gdf: gpd.GeoDataFrame, data_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Demonstrate validation checks after loading spatial data.\n",
    "    Returns a validation report.\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ” Validating loaded data: {data_name}\")\n",
    "    \n",
    "    validation_report = {\n",
    "        'is_valid': True,\n",
    "        'issues': [],\n",
    "        'warnings': []\n",
    "    }\n",
    "    \n",
    "    # Check 1: Is it actually a GeoDataFrame?\n",
    "    if not isinstance(gdf, gpd.GeoDataFrame):\n",
    "        validation_report['is_valid'] = False\n",
    "        validation_report['issues'].append(\"Not a GeoDataFrame\")\n",
    "        return validation_report\n",
    "    \n",
    "    print(f\"   âœ… Type: Valid GeoDataFrame\")\n",
    "    \n",
    "    # Check 2: Has data?\n",
    "    if len(gdf) == 0:\n",
    "        validation_report['warnings'].append(\"Dataset is empty\")\n",
    "        print(f\"   âš ï¸ Data: Empty dataset\")\n",
    "    else:\n",
    "        print(f\"   âœ… Data: {len(gdf)} features\")\n",
    "    \n",
    "    # Check 3: Has geometry column?\n",
    "    if 'geometry' not in gdf.columns:\n",
    "        validation_report['is_valid'] = False\n",
    "        validation_report['issues'].append(\"No geometry column\")\n",
    "        print(f\"   âŒ Geometry: Missing geometry column\")\n",
    "    else:\n",
    "        print(f\"   âœ… Geometry: Column present\")\n",
    "        \n",
    "        # Check geometry validity\n",
    "        if len(gdf) > 0:\n",
    "            valid_geoms = gdf.geometry.is_valid.sum()\n",
    "            total_geoms = len(gdf)\n",
    "            print(f\"   ðŸ“Š Valid geometries: {valid_geoms}/{total_geoms}\")\n",
    "            \n",
    "            if valid_geoms < total_geoms:\n",
    "                validation_report['warnings'].append(f\"{total_geoms - valid_geoms} invalid geometries\")\n",
    "    \n",
    "    # Check 4: Has CRS?\n",
    "    if gdf.crs is None:\n",
    "        validation_report['warnings'].append(\"No coordinate reference system defined\")\n",
    "        print(f\"   âš ï¸ CRS: Not defined\")\n",
    "    else:\n",
    "        print(f\"   âœ… CRS: {gdf.crs}\")\n",
    "    \n",
    "    # Check 5: Reasonable data ranges (for geographic data)\n",
    "    if gdf.crs and gdf.crs.to_epsg() == 4326 and len(gdf) > 0:  # WGS84\n",
    "        bounds = gdf.total_bounds\n",
    "        minx, miny, maxx, maxy = bounds\n",
    "        \n",
    "        if not (-180 <= minx <= 180 and -180 <= maxx <= 180):\n",
    "            validation_report['warnings'].append(\"Longitude values outside valid range\")\n",
    "            print(f\"   âš ï¸ Longitude range: {minx:.2f} to {maxx:.2f} (outside Â±180)\")\n",
    "        else:\n",
    "            print(f\"   âœ… Longitude range: {minx:.2f} to {maxx:.2f}\")\n",
    "            \n",
    "        if not (-90 <= miny <= 90 and -90 <= maxy <= 90):\n",
    "            validation_report['warnings'].append(\"Latitude values outside valid range\")\n",
    "            print(f\"   âš ï¸ Latitude range: {miny:.2f} to {maxy:.2f} (outside Â±90)\")\n",
    "        else:\n",
    "            print(f\"   âœ… Latitude range: {miny:.2f} to {maxy:.2f}\")\n",
    "    \n",
    "    # Summary\n",
    "    if validation_report['is_valid']:\n",
    "        if len(validation_report['warnings']) == 0:\n",
    "            print(f\"   ðŸŽ‰ Overall: EXCELLENT - No issues found!\")\n",
    "        else:\n",
    "            print(f\"   âœ… Overall: GOOD - {len(validation_report['warnings'])} warnings\")\n",
    "    else:\n",
    "        print(f\"   âŒ Overall: PROBLEMS - {len(validation_report['issues'])} critical issues\")\n",
    "    \n",
    "    return validation_report\n",
    "\n",
    "# Test validation on different datasets\n",
    "print(\"ðŸ§ª Testing data validation:\\n\")\n",
    "\n",
    "# Test 1: Clean data\n",
    "cities_clean = gpd.read_file('../data/cities/sample_cities.geojson')\n",
    "report1 = validate_loaded_data(cities_clean, \"Clean Cities\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test 2: Problematic data\n",
    "try:\n",
    "    cities_problems = gpd.read_file('../data/cities/cities_with_issues.geojson')\n",
    "    report2 = validate_loaded_data(cities_problems, \"Problematic Cities\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Failed to load problematic data: {e}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Validation helps identify data quality issues early in your workflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assignment_preparation",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Assignment Implementation Guide\n",
    "\n",
    "Now you're ready to implement the `load_spatial_dataset()` function! Here's your roadmap:\n",
    "\n",
    "### ðŸ“‹ Implementation Checklist\n",
    "\n",
    "Your function needs to:\n",
    "\n",
    "1. âœ… **Accept flexible input**: `Union[str, Path]` for file paths\n",
    "2. âœ… **Handle Path conversion**: Convert strings to Path objects\n",
    "3. âœ… **Check file existence**: Raise `FileNotFoundError` if missing\n",
    "4. âœ… **Validate file format**: Support common spatial formats\n",
    "5. âœ… **Load the data**: Use `gpd.read_file()` with error handling\n",
    "6. âœ… **Validate results**: Ensure it's a valid GeoDataFrame\n",
    "7. âœ… **Handle kwargs**: Pass additional parameters to GeoPandas\n",
    "8. âœ… **Return GeoDataFrame**: Return the loaded spatial data\n",
    "\n",
    "### ðŸ’» Code Structure Template\n",
    "\n",
    "```python\n",
    "def load_spatial_dataset(file_path: Union[str, Path], **kwargs) -> gpd.GeoDataFrame:\n",
    "    # Step 1: Convert to Path object\n",
    "    path_obj = Path(file_path)\n",
    "    \n",
    "    # Step 2: Check existence\n",
    "    if not path_obj.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path_obj}\")\n",
    "    \n",
    "    # Step 3: Validate format (optional but recommended)\n",
    "    # Check file extension\n",
    "    \n",
    "    # Step 4: Load data with error handling\n",
    "    try:\n",
    "        gdf = gpd.read_file(path_obj, **kwargs)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading spatial data: {e}\")\n",
    "    \n",
    "    # Step 5: Validate result\n",
    "    # Check it's a GeoDataFrame, has geometry, etc.\n",
    "    \n",
    "    # Step 6: Return the data\n",
    "    return gdf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "testing_your_function",
   "metadata": {},
   "source": [
    "## ðŸ§ª Testing Your Implementation\n",
    "\n",
    "After implementing your function, test it with these scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_scenarios",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§ª Test scenarios for your load_spatial_dataset() function\n",
    "# Uncomment these after implementing your function!\n",
    "\n",
    "# from src.spatial_basics import load_spatial_dataset\n",
    "\n",
    "print(\"ðŸ§ª Test Scenarios for load_spatial_dataset()\\n\")\n",
    "\n",
    "# Test cases you should handle:\n",
    "test_cases = [\n",
    "    \"âœ… Valid GeoJSON file with string path\",\n",
    "    \"âœ… Valid Shapefile with Path object\", \n",
    "    \"âœ… Loading with additional kwargs (encoding)\",\n",
    "    \"âŒ Non-existent file (should raise FileNotFoundError)\",\n",
    "    \"âŒ Invalid file format (should raise ValueError)\",\n",
    "    \"âš ï¸ File with data quality issues (should load but warn)\"\n",
    "]\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"{i}. {test_case}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Run: uv run pytest tests/ -k 'load_spatial_dataset' -v\")\n",
    "print(\"   This will test your implementation automatically!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "key_concepts",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Key Concepts Summary\n",
    "\n",
    "### âœ… What You've Learned:\n",
    "\n",
    "**ðŸ“ File Path Handling**\n",
    "- Using `pathlib.Path` for robust path management\n",
    "- Converting between strings and Path objects\n",
    "- Checking file existence before loading\n",
    "\n",
    "**ðŸ—‚ï¸ Spatial Data Formats**\n",
    "- GeoJSON: Web-friendly, single file, human-readable\n",
    "- Shapefile: Traditional GIS, multiple files, compact\n",
    "- Understanding when to use each format\n",
    "\n",
    "**âš ï¸ Error Handling**\n",
    "- `FileNotFoundError` for missing files\n",
    "- `ValueError` for invalid data or formats\n",
    "- Using try/except blocks for graceful failure\n",
    "\n",
    "**âœ… Data Validation**\n",
    "- Checking data type (GeoDataFrame)\n",
    "- Verifying geometry column exists\n",
    "- Validating coordinate ranges\n",
    "- CRS presence and validity\n",
    "\n",
    "**ðŸ”§ Professional Practices**\n",
    "- Using type hints (`Union[str, Path]`)\n",
    "- Supporting flexible parameters (`**kwargs`)\n",
    "- Comprehensive error messages\n",
    "- Step-by-step validation workflow\n",
    "\n",
    "### ðŸš€ Skills for Your GIS Career:\n",
    "- **Data Pipeline Development**: Building robust data loading functions\n",
    "- **Error Handling**: Making code that works with messy real-world data  \n",
    "- **Format Expertise**: Understanding spatial data format trade-offs\n",
    "- **Quality Assurance**: Validating data immediately after loading\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Next Steps\n",
    "\n",
    "### ðŸŽ¯ Immediate Actions:\n",
    "1. **Implement** `load_spatial_dataset()` in `src/spatial_basics.py`\n",
    "2. **Test** with: `uv run pytest tests/ -k \"load_spatial_dataset\" -v`\n",
    "3. **Debug** any failing tests using the error messages\n",
    "4. **Validate** with different file formats and scenarios\n",
    "\n",
    "### ðŸ“– Continue Learning:\n",
    "- **Next Notebook**: `03_explore_properties.ipynb` - Analyze spatial characteristics\n",
    "- **Build on**: This loading foundation for all future spatial analysis\n",
    "- **Practice**: Try loading your own spatial datasets!\n",
    "\n",
    "### ðŸ’¡ Pro Tips:\n",
    "- **Always validate** loaded data before analysis\n",
    "- **Handle errors gracefully** - real data is messy\n",
    "- **Use Path objects** - they prevent many path-related bugs\n",
    "- **Test edge cases** - empty files, missing files, wrong formats\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸŽ‰ Congratulations!** You now understand professional spatial data loading. This is the foundation skill that supports all GIS programming work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick_reference_loading",
   "metadata": {},
   "source": [
    "## ðŸ”– Quick Reference - Loading Commands\n",
    "\n",
    "```python\n",
    "# Basic loading\n",
    "gdf = gpd.read_file('data/file.geojson')\n",
    "gdf = gpd.read_file('data/file.shp')\n",
    "\n",
    "# With Path objects (recommended)\n",
    "from pathlib import Path\n",
    "file_path = Path('data/file.geojson')\n",
    "gdf = gpd.read_file(file_path)\n",
    "\n",
    "# With additional parameters\n",
    "gdf = gpd.read_file('file.geojson', encoding='utf-8')\n",
    "gdf = gpd.read_file('file.shp', columns=['name', 'geometry'])\n",
    "\n",
    "# Error handling\n",
    "try:\n",
    "    gdf = gpd.read_file('file.geojson')\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found\")\n",
    "except Exception as e:\n",
    "    print(f\"Loading error: {e}\")\n",
    "\n",
    "# Basic validation\n",
    "assert isinstance(gdf, gpd.GeoDataFrame)\n",
    "assert 'geometry' in gdf.columns\n",
    "assert len(gdf) > 0\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
