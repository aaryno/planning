{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ Function 1: Load Spatial Datasets\n",
    "\n",
    "## Building the `load_spatial_dataset` Function\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand different spatial data formats and their characteristics\n",
    "- Learn to load spatial data using GeoPandas\n",
    "- Handle common file loading issues and encoding problems\n",
    "- Validate spatial data after loading\n",
    "- Work with various coordinate reference systems\n",
    "- Implement robust error handling for spatial data operations\n",
    "\n",
    "**Professional Context:**\n",
    "Loading spatial data is the foundation of all GIS workflows. Professionals need to:\n",
    "- **Handle Multiple Formats** - Shapefiles, GeoJSON, GeoPackage, KML, etc.\n",
    "- **Manage Data Quality** - Validate geometry and handle corrupted files\n",
    "- **Deal with Encoding Issues** - International characters and different standards\n",
    "- **Integrate Data Sources** - Combine data from various providers and formats\n",
    "- **Ensure Reliability** - Robust error handling for production workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Spatial Data Formats\n",
    "\n",
    "### 1.1 Common Spatial Vector Formats\n",
    "\n",
    "**Shapefile (.shp)**\n",
    "- Most common legacy format\n",
    "- Actually multiple files (.shp, .shx, .dbf, .prj, etc.)\n",
    "- Limited column names (10 characters)\n",
    "- Encoding issues common\n",
    "\n",
    "**GeoJSON (.geojson, .json)**\n",
    "- Web-friendly format\n",
    "- Human-readable text format\n",
    "- Always uses WGS84 (EPSG:4326) coordinates\n",
    "- Good for web applications\n",
    "\n",
    "**GeoPackage (.gpkg)**\n",
    "- Modern OGC standard\n",
    "- Single file format\n",
    "- Supports multiple layers\n",
    "- No attribute limitations\n",
    "\n",
    "**Other Formats:**\n",
    "- KML/KMZ (Google Earth)\n",
    "- CSV with coordinates\n",
    "- PostGIS databases\n",
    "- File geodatabases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import os\n",
    "import warnings\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import json\n",
    "\n",
    "# Create sample datasets in different formats for demonstration\n",
    "def create_sample_spatial_data():\n",
    "    \"\"\"Create sample spatial datasets in different formats.\"\"\"\n",
    "    \n",
    "    # Create sample point data (cities)\n",
    "    cities_data = {\n",
    "        'name': ['San Francisco', 'Los Angeles', 'San Diego', 'Sacramento', 'Fresno'],\n",
    "        'population': [884363, 3979576, 1425976, 508529, 542107],\n",
    "        'state': ['CA', 'CA', 'CA', 'CA', 'CA'],\n",
    "        'geometry': [\n",
    "            Point(-122.4194, 37.7749),  # San Francisco\n",
    "            Point(-118.2437, 34.0522),  # Los Angeles\n",
    "            Point(-117.1611, 32.7157),  # San Diego\n",
    "            Point(-121.4944, 38.5816),  # Sacramento\n",
    "            Point(-119.7871, 36.7378)   # Fresno\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    cities_gdf = gpd.GeoDataFrame(cities_data, crs='EPSG:4326')\n",
    "    \n",
    "    # Create sample line data (simplified roads)\n",
    "    roads_data = {\n",
    "        'name': ['Highway 101', 'Interstate 5', 'Highway 1'],\n",
    "        'type': ['Highway', 'Interstate', 'Highway'],\n",
    "        'geometry': [\n",
    "            LineString([(-122.4, 37.8), (-118.2, 34.0)]),  # SF to LA\n",
    "            LineString([(-118.2, 34.0), (-117.2, 32.7)]),  # LA to SD\n",
    "            LineString([(-122.4, 37.8), (-121.9, 36.6)])   # SF to Monterey\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    roads_gdf = gpd.GeoDataFrame(roads_data, crs='EPSG:4326')\n",
    "    \n",
    "    # Create sample polygon data (counties)\n",
    "    counties_data = {\n",
    "        'name': ['San Francisco County', 'Los Angeles County'],\n",
    "        'area_km2': [121, 12305],\n",
    "        'geometry': [\n",
    "            Polygon([(-122.5, 37.7), (-122.3, 37.7), (-122.3, 37.8), (-122.5, 37.8)]),\n",
    "            Polygon([(-118.5, 33.9), (-118.0, 33.9), (-118.0, 34.2), (-118.5, 34.2)])\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    counties_gdf = gpd.GeoDataFrame(counties_data, crs='EPSG:4326')\n",
    "    \n",
    "    return cities_gdf, roads_gdf, counties_gdf\n",
    "\n",
    "# Create the sample data\n",
    "cities_gdf, roads_gdf, counties_gdf = create_sample_spatial_data()\n",
    "\n",
    "print(\"Created sample spatial datasets:\")\n",
    "print(f\"Cities: {len(cities_gdf)} points\")\n",
    "print(f\"Roads: {len(roads_gdf)} lines\")\n",
    "print(f\"Counties: {len(counties_gdf)} polygons\")\n",
    "\n",
    "# Display basic info about each dataset\n",
    "print(\"\\n=== CITIES DATA ===\")\n",
    "print(cities_gdf.head())\n",
    "print(f\"CRS: {cities_gdf.crs}\")\n",
    "print(f\"Geometry types: {cities_gdf.geometry.geom_type.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Saving Data in Different Formats\n",
    "\n",
    "Let's save our sample data in different formats to demonstrate loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary directory for sample files\n",
    "temp_dir = Path(tempfile.mkdtemp())\n",
    "print(f\"Sample data directory: {temp_dir}\")\n",
    "\n",
    "# Save data in different formats\n",
    "sample_files = {}\n",
    "\n",
    "# 1. Shapefile\n",
    "shapefile_path = temp_dir / \"cities.shp\"\n",
    "cities_gdf.to_file(shapefile_path, driver='ESRI Shapefile')\n",
    "sample_files['shapefile'] = shapefile_path\n",
    "\n",
    "# 2. GeoJSON\n",
    "geojson_path = temp_dir / \"roads.geojson\"\n",
    "roads_gdf.to_file(geojson_path, driver='GeoJSON')\n",
    "sample_files['geojson'] = geojson_path\n",
    "\n",
    "# 3. GeoPackage\n",
    "gpkg_path = temp_dir / \"data.gpkg\"\n",
    "counties_gdf.to_file(gpkg_path, driver='GPKG', layer='counties')\n",
    "sample_files['geopackage'] = gpkg_path\n",
    "\n",
    "# 4. CSV with coordinates (not truly spatial, but common)\n",
    "csv_path = temp_dir / \"cities_coords.csv\"\n",
    "cities_csv = cities_gdf.copy()\n",
    "cities_csv['longitude'] = cities_csv.geometry.x\n",
    "cities_csv['latitude'] = cities_csv.geometry.y\n",
    "cities_csv.drop('geometry', axis=1).to_csv(csv_path, index=False)\n",
    "sample_files['csv'] = csv_path\n",
    "\n",
    "print(\"\\nCreated sample files:\")\n",
    "for format_name, file_path in sample_files.items():\n",
    "    print(f\"  {format_name}: {file_path}\")\n",
    "    print(f\"    Exists: {file_path.exists()}\")\n",
    "    if file_path.exists():\n",
    "        print(f\"    Size: {file_path.stat().st_size} bytes\")\n",
    "\n",
    "# List all files in temp directory to see shapefile components\n",
    "print(f\"\\nAll files in {temp_dir}:\")\n",
    "for file in sorted(temp_dir.glob('*')):\n",
    "    print(f\"  {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Loading Spatial Data with GeoPandas\n",
    "\n",
    "### 2.1 Basic Loading Operations\n",
    "\n",
    "GeoPandas provides the `read_file()` function to load most spatial formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate basic loading for different formats\n",
    "print(\"=== LOADING DIFFERENT FORMATS ===\")\n",
    "\n",
    "# 1. Load Shapefile\n",
    "try:\n",
    "    cities_loaded = gpd.read_file(sample_files['shapefile'])\n",
    "    print(f\"\\nShapefile loaded successfully:\")\n",
    "    print(f\"  Shape: {cities_loaded.shape}\")\n",
    "    print(f\"  CRS: {cities_loaded.crs}\")\n",
    "    print(f\"  Columns: {list(cities_loaded.columns)}\")\n",
    "    print(f\"  Geometry type: {cities_loaded.geometry.geom_type.unique()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading shapefile: {e}\")\n",
    "\n",
    "# 2. Load GeoJSON\n",
    "try:\n",
    "    roads_loaded = gpd.read_file(sample_files['geojson'])\n",
    "    print(f\"\\nGeoJSON loaded successfully:\")\n",
    "    print(f\"  Shape: {roads_loaded.shape}\")\n",
    "    print(f\"  CRS: {roads_loaded.crs}\")\n",
    "    print(f\"  Columns: {list(roads_loaded.columns)}\")\n",
    "    print(f\"  Geometry type: {roads_loaded.geometry.geom_type.unique()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading GeoJSON: {e}\")\n",
    "\n",
    "# 3. Load GeoPackage\n",
    "try:\n",
    "    counties_loaded = gpd.read_file(sample_files['geopackage'], layer='counties')\n",
    "    print(f\"\\nGeoPackage loaded successfully:\")\n",
    "    print(f\"  Shape: {counties_loaded.shape}\")\n",
    "    print(f\"  CRS: {counties_loaded.crs}\")\n",
    "    print(f\"  Columns: {list(counties_loaded.columns)}\")\n",
    "    print(f\"  Geometry type: {counties_loaded.geometry.geom_type.unique()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading GeoPackage: {e}\")\n",
    "\n",
    "# 4. Creating GeoDataFrame from CSV (manual process)\n",
    "try:\n",
    "    # Load CSV as regular DataFrame\n",
    "    cities_csv = pd.read_csv(sample_files['csv'])\n",
    "    \n",
    "    # Convert to GeoDataFrame\n",
    "    cities_from_csv = gpd.GeoDataFrame(\n",
    "        cities_csv,\n",
    "        geometry=gpd.points_from_xy(cities_csv.longitude, cities_csv.latitude),\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCSV converted to GeoDataFrame:\")\n",
    "    print(f\"  Shape: {cities_from_csv.shape}\")\n",
    "    print(f\"  CRS: {cities_from_csv.crs}\")\n",
    "    print(f\"  Columns: {list(cities_from_csv.columns)}\")\n",
    "    print(f\"  Geometry type: {cities_from_csv.geometry.geom_type.unique()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Handling File Format Detection\n",
    "\n",
    "GeoPandas can often auto-detect file formats, but it's good practice to be explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate format detection and explicit driver specification\n",
    "def detect_and_load_format(file_path):\n",
    "    \"\"\"Demonstrate format detection logic.\"\"\"\n",
    "    \n",
    "    file_path = Path(file_path)\n",
    "    extension = file_path.suffix.lower()\n",
    "    \n",
    "    print(f\"\\n=== LOADING: {file_path.name} ===\")\n",
    "    print(f\"Extension: {extension}\")\n",
    "    \n",
    "    # Determine appropriate driver\n",
    "    if extension == '.shp':\n",
    "        driver = 'ESRI Shapefile'\n",
    "        print(f\"Detected format: Shapefile\")\n",
    "    elif extension in ['.geojson', '.json']:\n",
    "        driver = 'GeoJSON'\n",
    "        print(f\"Detected format: GeoJSON\")\n",
    "    elif extension == '.gpkg':\n",
    "        driver = 'GPKG'\n",
    "        print(f\"Detected format: GeoPackage\")\n",
    "    elif extension == '.kml':\n",
    "        driver = 'KML'\n",
    "        print(f\"Detected format: KML\")\n",
    "    else:\n",
    "        driver = None\n",
    "        print(f\"Unknown format, will let GeoPandas auto-detect\")\n",
    "    \n",
    "    try:\n",
    "        # Load with explicit driver if known\n",
    "        if driver:\n",
    "            gdf = gpd.read_file(file_path, driver=driver)\n",
    "            print(f\"âœ“ Loaded with driver: {driver}\")\n",
    "        else:\n",
    "            gdf = gpd.read_file(file_path)\n",
    "            print(f\"âœ“ Loaded with auto-detection\")\n",
    "        \n",
    "        # Report success\n",
    "        print(f\"  Records: {len(gdf)}\")\n",
    "        print(f\"  Columns: {len(gdf.columns)}\")\n",
    "        print(f\"  CRS: {gdf.crs}\")\n",
    "        print(f\"  Geometry column: '{gdf.geometry.name}'\")\n",
    "        \n",
    "        return gdf\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error loading file: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Test with our sample files\n",
    "for format_name, file_path in sample_files.items():\n",
    "    if format_name != 'csv':  # Skip CSV as it's not a spatial format\n",
    "        loaded_gdf = detect_and_load_format(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Error Handling and Common Issues\n",
    "\n",
    "### 3.1 Common Loading Problems\n",
    "\n",
    "Professional spatial data loading must handle various issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate common loading problems and solutions\n",
    "def demonstrate_common_issues():\n",
    "    \"\"\"Show common spatial data loading issues and solutions.\"\"\"\n",
    "    \n",
    "    print(\"=== COMMON LOADING ISSUES ===\")\n",
    "    \n",
    "    # Issue 1: File not found\n",
    "    print(\"\\n1. File Not Found Error:\")\n",
    "    try:\n",
    "        missing_gdf = gpd.read_file('/nonexistent/path/to/file.shp')\n",
    "    except Exception as e:\n",
    "        print(f\"   Error: {type(e).__name__}: {e}\")\n",
    "        print(f\"   Solution: Check file path and existence\")\n",
    "    \n",
    "    # Issue 2: Encoding problems (simulate with a special character file)\n",
    "    print(\"\\n2. Encoding Issues:\")\n",
    "    # Create a shapefile with special characters\n",
    "    special_data = {\n",
    "        'name': ['MÃ©xico', 'SÃ£o Paulo', 'MÃ¼nchen'],\n",
    "        'country': ['MÃ©xico', 'Brasil', 'Deutschland'],\n",
    "        'geometry': [\n",
    "            Point(-99.1332, 19.4326),\n",
    "            Point(-46.6333, -23.5505),\n",
    "            Point(11.5820, 48.1351)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    special_gdf = gpd.GeoDataFrame(special_data, crs='EPSG:4326')\n",
    "    special_path = temp_dir / 'special_chars.shp'\n",
    "    \n",
    "    try:\n",
    "        # Save with UTF-8 encoding\n",
    "        special_gdf.to_file(special_path, encoding='utf-8')\n",
    "        \n",
    "        # Try loading with different encodings\n",
    "        print(\"   Trying UTF-8 encoding:\")\n",
    "        loaded_special = gpd.read_file(special_path, encoding='utf-8')\n",
    "        print(f\"   âœ“ Success: {loaded_special['name'].tolist()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   Error with encoding: {e}\")\n",
    "        print(f\"   Solution: Try different encodings (utf-8, latin-1, cp1252)\")\n",
    "    \n",
    "    # Issue 3: Invalid geometries\n",
    "    print(\"\\n3. Invalid Geometries:\")\n",
    "    try:\n",
    "        # Create a dataset with a potentially invalid geometry\n",
    "        from shapely.geometry import Polygon\n",
    "        \n",
    "        # Self-intersecting polygon (invalid)\n",
    "        invalid_geom = Polygon([(0, 0), (1, 1), (1, 0), (0, 1), (0, 0)])\n",
    "        \n",
    "        invalid_data = {\n",
    "            'name': ['Valid Area', 'Invalid Area'],\n",
    "            'geometry': [\n",
    "                Polygon([(0, 0), (1, 0), (1, 1), (0, 1)]),  # Valid square\n",
    "                invalid_geom  # Invalid self-intersecting\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        invalid_gdf = gpd.GeoDataFrame(invalid_data, crs='EPSG:4326')\n",
    "        \n",
    "        # Check for invalid geometries\n",
    "        validity_check = invalid_gdf.geometry.is_valid\n",
    "        print(f\"   Geometry validity: {validity_check.tolist()}\")\n",
    "        print(f\"   Invalid count: {(~validity_check).sum()}\")\n",
    "        \n",
    "        if not validity_check.all():\n",
    "            print(\"   Solution: Use .buffer(0) or validate geometries after loading\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   Error creating invalid geometry example: {e}\")\n",
    "    \n",
    "    # Issue 4: Missing CRS\n",
    "    print(\"\\n4. Missing Coordinate Reference System:\")\n",
    "    try:\n",
    "        # Create data without CRS\n",
    "        no_crs_gdf = gpd.GeoDataFrame(\n",
    "            {'name': ['Point1'], 'geometry': [Point(0, 0)]}\n",
    "            # Note: no crs parameter\n",
    "        )\n",
    "        \n",
    "        print(f\"   CRS: {no_crs_gdf.crs}\")\n",
    "        if no_crs_gdf.crs is None:\n",
    "            print(\"   Warning: No CRS defined\")\n",
    "            print(\"   Solution: Set CRS explicitly or assume common CRS (EPSG:4326)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   Error with CRS example: {e}\")\n",
    "\n",
    "# Run the demonstration\n",
    "demonstrate_common_issues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Robust Loading Function Example\n",
    "\n",
    "Let's build a robust loading function that handles common issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spatial_dataset_example(file_path, **kwargs):\n",
    "    \"\"\"Example implementation with robust error handling.\"\"\"\n",
    "    \n",
    "    # Step 1: Convert to Path object and validate\n",
    "    file_path = Path(file_path)\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"Spatial data file not found: {file_path}\")\n",
    "    \n",
    "    # Step 2: Determine file format\n",
    "    extension = file_path.suffix.lower()\n",
    "    \n",
    "    # Step 3: Try different loading approaches based on format\n",
    "    try:\n",
    "        # First attempt: Use GeoPandas read_file with kwargs\n",
    "        gdf = gpd.read_file(file_path, **kwargs)\n",
    "        \n",
    "    except UnicodeDecodeError:\n",
    "        # Handle encoding issues\n",
    "        print(\"Warning: Encoding issue detected, trying different encodings...\")\n",
    "        \n",
    "        encodings_to_try = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
    "        \n",
    "        for encoding in encodings_to_try:\n",
    "            try:\n",
    "                print(f\"  Trying encoding: {encoding}\")\n",
    "                gdf = gpd.read_file(file_path, encoding=encoding, **kwargs)\n",
    "                print(f\"  âœ“ Success with encoding: {encoding}\")\n",
    "                break\n",
    "            except (UnicodeDecodeError, Exception):\n",
    "                continue\n",
    "        else:\n",
    "            raise ValueError(f\"Could not read file with any standard encoding: {file_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle other loading errors\n",
    "        raise ValueError(f\"Error loading spatial file {file_path}: {str(e)}\")\n",
    "    \n",
    "    # Step 4: Validate the loaded data\n",
    "    if not isinstance(gdf, gpd.GeoDataFrame):\n",
    "        raise ValueError(f\"Loaded data is not a GeoDataFrame: {type(gdf)}\")\n",
    "    \n",
    "    if len(gdf) == 0:\n",
    "        raise ValueError(f\"Loaded GeoDataFrame is empty: {file_path}\")\n",
    "    \n",
    "    if 'geometry' not in gdf.columns:\n",
    "        raise ValueError(f\"No geometry column found in: {file_path}\")\n",
    "    \n",
    "    # Step 5: Check for and warn about common issues\n",
    "    if gdf.crs is None:\n",
    "        print(f\"Warning: No CRS defined for {file_path}. Consider setting CRS explicitly.\")\n",
    "    \n",
    "    # Check for invalid geometries\n",
    "    if hasattr(gdf.geometry, 'is_valid'):\n",
    "        invalid_count = (~gdf.geometry.is_valid).sum()\n",
    "        if invalid_count > 0:\n",
    "            print(f\"Warning: {invalid_count} invalid geometries found in {file_path}\")\n",
    "    \n",
    "    # Check for null geometries\n",
    "    null_geom_count = gdf.geometry.isna().sum()\n",
    "    if null_geom_count > 0:\n",
    "        print(f\"Warning: {null_geom_count} null geometries found in {file_path}\")\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "# Test the robust loading function\n",
    "print(\"=== TESTING ROBUST LOADING FUNCTION ===\")\n",
    "\n",
    "for format_name, file_path in sample_files.items():\n",
    "    if format_name != 'csv':  # Skip CSV as it's not directly spatial\n",
    "        try:\n",
    "            print(f\"\\nTesting {format_name}: {file_path.name}\")\n",
    "            \n",
    "            # Handle GeoPackage layer specification\n",
    "            if format_name == 'geopackage':\n",
    "                loaded_gdf = load_spatial_dataset_example(file_path, layer='counties')\n",
    "            else:\n",
    "                loaded_gdf = load_spatial_dataset_example(file_path)\n",
    "            \n",
    "            print(f\"  âœ“ Successfully loaded {len(loaded_gdf)} features\")\n",
    "            print(f\"    Columns: {list(loaded_gdf.columns)}\")\n",
    "            print(f\"    CRS: {loaded_gdf.crs}\")\n",
    "            print(f\"    Geometry types: {loaded_gdf.geometry.geom_type.unique().tolist()}\")\n",
