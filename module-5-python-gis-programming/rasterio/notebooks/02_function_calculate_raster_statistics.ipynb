{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Function 2: Calculate Raster Statistics\n",
    "\n",
    "## Building the `calculate_raster_statistics` Function\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand statistical analysis for raster datasets\n",
    "- Learn to handle NoData values properly in statistical calculations\n",
    "- Master numpy statistical functions for geospatial data\n",
    "- Calculate comprehensive data distribution metrics\n",
    "- Assess data quality and identify outliers\n",
    "- Work with different data types and value ranges\n",
    "\n",
    "**Professional Context:**\n",
    "Statistical analysis is essential for:\n",
    "- **Data Quality Assessment** - Identifying unusual values and data errors\n",
    "- **Processing Parameter Selection** - Understanding data ranges for analysis\n",
    "- **Change Detection** - Comparing statistics between time periods\n",
    "- **Classification Preparation** - Understanding data distribution for clustering\n",
    "- **Report Generation** - Providing summary statistics for stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Raster Statistics\n",
    "\n",
    "### 1.1 Why Statistics Matter for Raster Data\n",
    "\n",
    "Raster statistics help us understand:\n",
    "- **Data Distribution**: Are values normally distributed or skewed?\n",
    "- **Data Range**: What are the minimum and maximum values?\n",
    "- **Data Quality**: Are there unexpected values or missing data?\n",
    "- **Processing Needs**: Do values need scaling or normalization?\n",
    "\n",
    "### 1.2 Common Raster Statistics\n",
    "\n",
    "**Basic Statistics:**\n",
    "- Min/Max: Data range and extremes\n",
    "- Mean: Central tendency\n",
    "- Standard Deviation: Data spread\n",
    "- Median: Middle value (robust to outliers)\n",
    "\n",
    "**Distribution Statistics:**\n",
    "- Percentiles: Data distribution characteristics\n",
    "- Range: Total data spread\n",
    "- Valid pixel count: Data completeness assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import os\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Create sample raster data with different characteristics\n",
    "def create_statistical_test_data():\n",
    "    \"\"\"Create raster data with known statistical properties for demonstration.\"\"\"\n",
    "    \n",
    "    # Create different types of data\n",
    "    width, height = 100, 100\n",
    "    \n",
    "    # Dataset 1: Normal distribution (temperature data)\n",
    "    temp_data = np.random.normal(25, 5, (height, width))  # Mean=25Â°C, Std=5Â°C\n",
    "    \n",
    "    # Add some NoData values\n",
    "    nodata_mask = np.random.random((height, width)) < 0.1  # 10% NoData\n",
    "    temp_data[nodata_mask] = -9999\n",
    "    \n",
    "    # Transform for spatial reference\n",
    "    transform = rasterio.transform.from_bounds(\n",
    "        west=-120.0, south=35.0, east=-119.0, north=36.0,\n",
    "        width=width, height=height\n",
    "    )\n",
    "    \n",
    "    # Save temperature raster\n",
    "    temp_path = tempfile.mktemp(suffix='_temperature.tif')\n",
    "    with rasterio.open(\n",
    "        temp_path, 'w',\n",
    "        driver='GTiff', height=height, width=width, count=1,\n",
    "        dtype=temp_data.dtype, crs='EPSG:4326', transform=transform,\n",
    "        nodata=-9999\n",
    "    ) as dst:\n",
    "        dst.write(temp_data, 1)\n",
    "    \n",
    "    # Dataset 2: Elevation data with different distribution\n",
    "    x = np.linspace(0, 4*np.pi, width)\n",
    "    y = np.linspace(0, 4*np.pi, height)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    elevation_data = 1000 + 500 * np.sin(X) * np.cos(Y) + np.random.normal(0, 50, (height, width))\n",
    "    \n",
    "    # Convert to integer (typical for elevation)\n",
    "    elevation_data = elevation_data.astype(np.int16)\n",
    "    \n",
    "    # Add NoData in water areas (simulate ocean)\n",
    "    water_mask = elevation_data < 200\n",
    "    elevation_data[water_mask] = -32768  # Common NoData for int16\n",
    "    \n",
    "    # Save elevation raster\n",
    "    elev_path = tempfile.mktemp(suffix='_elevation.tif')\n",
    "    with rasterio.open(\n",
    "        elev_path, 'w',\n",
    "        driver='GTiff', height=height, width=width, count=1,\n",
    "        dtype=elevation_data.dtype, crs='EPSG:4326', transform=transform,\n",
    "        nodata=-32768\n",
    "    ) as dst:\n",
    "        dst.write(elevation_data, 1)\n",
    "    \n",
    "    return temp_path, elev_path\n",
    "\n",
    "# Create test data\n",
    "temp_raster, elev_raster = create_statistical_test_data()\n",
    "print(f\"Created temperature raster: {temp_raster}\")\n",
    "print(f\"Created elevation raster: {elev_raster}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Reading Raster Data for Analysis\n",
    "\n",
    "Before calculating statistics, we need to read the raster data correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read temperature data\n",
    "with rasterio.open(temp_raster) as src:\n",
    "    temp_data = src.read(1)  # Read band 1\n",
    "    temp_nodata = src.nodata\n",
    "    \n",
    "    print(f\"Temperature data shape: {temp_data.shape}\")\n",
    "    print(f\"Temperature data type: {temp_data.dtype}\")\n",
    "    print(f\"Temperature NoData value: {temp_nodata}\")\n",
    "    print(f\"Temperature data range (with NoData): {temp_data.min()} to {temp_data.max()}\")\n",
    "\n",
    "# Read elevation data  \n",
    "with rasterio.open(elev_raster) as src:\n",
    "    elev_data = src.read(1)\n",
    "    elev_nodata = src.nodata\n",
    "    \n",
    "    print(f\"\\nElevation data shape: {elev_data.shape}\")\n",
    "    print(f\"Elevation data type: {elev_data.dtype}\")\n",
    "    print(f\"Elevation NoData value: {elev_nodata}\")\n",
    "    print(f\"Elevation data range (with NoData): {elev_data.min()} to {elev_data.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 The Critical Importance of NoData Handling\n",
    "\n",
    "**NoData values can completely skew statistics if not handled properly!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the impact of NoData on statistics\n",
    "print(\"=== IMPACT OF NODATA VALUES ===\")\n",
    "print(\"\\nTemperature data statistics:\")\n",
    "\n",
    "# WRONG: Include NoData values\n",
    "print(\"\\nINCLUDING NoData values (-9999):\")\n",
    "print(f\"  Mean: {np.mean(temp_data):.2f}Â°C\")\n",
    "print(f\"  Min: {np.min(temp_data):.2f}Â°C\")\n",
    "print(f\"  Max: {np.max(temp_data):.2f}Â°C\")\n",
    "print(f\"  Std: {np.std(temp_data):.2f}Â°C\")\n",
    "\n",
    "# RIGHT: Exclude NoData values\n",
    "valid_temps = temp_data[temp_data != temp_nodata]\n",
    "print(\"\\nEXCLUDING NoData values:\")\n",
    "print(f\"  Mean: {np.mean(valid_temps):.2f}Â°C\")\n",
    "print(f\"  Min: {np.min(valid_temps):.2f}Â°C\")\n",
    "print(f\"  Max: {np.max(valid_temps):.2f}Â°C\")\n",
    "print(f\"  Std: {np.std(valid_temps):.2f}Â°C\")\n",
    "\n",
    "print(f\"\\nValid pixels: {len(valid_temps):,} out of {temp_data.size:,} total\")\n",
    "print(f\"NoData pixels: {temp_data.size - len(valid_temps):,} ({100 * (temp_data.size - len(valid_temps)) / temp_data.size:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing Statistical Calculations\n",
    "\n",
    "### 2.1 Basic Statistical Functions\n",
    "\n",
    "Let's implement each statistical measure step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_comprehensive_stats(data_array, nodata_value=None, exclude_nodata=True):\n",
    "    \"\"\"Calculate comprehensive statistics for a data array.\"\"\"\n",
    "    \n",
    "    # Handle NoData values\n",
    "    if exclude_nodata and nodata_value is not None:\n",
    "        valid_mask = data_array != nodata_value\n",
    "        valid_data = data_array[valid_mask]\n",
    "    else:\n",
    "        valid_data = data_array.flatten()\n",
    "    \n",
    "    # Calculate pixel counts\n",
    "    total_pixels = data_array.size\n",
    "    valid_pixels = len(valid_data)\n",
    "    nodata_pixels = total_pixels - valid_pixels\n",
    "    \n",
    "    # If no valid data, return None values\n",
    "    if valid_pixels == 0:\n",
    "        return {\n",
    "            'min': None, 'max': None, 'mean': None, 'median': None,\n",
    "            'std': None, 'range': None, 'percentile_25': None, 'percentile_75': None,\n",
    "            'valid_pixels': 0, 'total_pixels': total_pixels, 'nodata_pixels': nodata_pixels\n",
    "        }\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        'min': float(np.min(valid_data)),\n",
    "        'max': float(np.max(valid_data)),\n",
    "        'mean': float(np.mean(valid_data)),\n",
    "        'median': float(np.median(valid_data)),\n",
    "        'std': float(np.std(valid_data)),\n",
    "        'range': float(np.ptp(valid_data)),  # peak-to-peak (max - min)\n",
    "        'percentile_25': float(np.percentile(valid_data, 25)),\n",
    "        'percentile_75': float(np.percentile(valid_data, 75)),\n",
    "        'valid_pixels': int(valid_pixels),\n",
    "        'total_pixels': int(total_pixels),\n",
    "        'nodata_pixels': int(nodata_pixels)\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Test with temperature data\n",
    "temp_stats = calculate_comprehensive_stats(temp_data, temp_nodata, exclude_nodata=True)\n",
    "\n",
    "print(\"=== TEMPERATURE STATISTICS ===\")\n",
    "for key, value in temp_stats.items():\n",
    "    if value is not None and key in ['min', 'max', 'mean', 'median', 'std', 'range', 'percentile_25', 'percentile_75']:\n",
    "        print(f\"{key}: {value:.2f}Â°C\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Visualizing Statistical Distributions\n",
    "\n",
    "Understanding data distribution helps interpret statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of data distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Temperature data\n",
    "valid_temps = temp_data[temp_data != temp_nodata]\n",
    "axes[0, 0].hist(valid_temps, bins=30, alpha=0.7, color='red', edgecolor='black')\n",
    "axes[0, 0].axvline(temp_stats['mean'], color='blue', linestyle='--', label=f\"Mean: {temp_stats['mean']:.1f}Â°C\")\n",
    "axes[0, 0].axvline(temp_stats['median'], color='green', linestyle='--', label=f\"Median: {temp_stats['median']:.1f}Â°C\")\n",
    "axes[0, 0].set_title('Temperature Distribution')\n",
    "axes[0, 0].set_xlabel('Temperature (Â°C)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Temperature raster visualization\n",
    "temp_display = temp_data.copy()\n",
    "temp_display[temp_display == temp_nodata] = np.nan  # Set NoData to NaN for display\n",
    "im1 = axes[0, 1].imshow(temp_display, cmap='coolwarm', interpolation='nearest')\n",
    "axes[0, 1].set_title('Temperature Raster')\n",
    "plt.colorbar(im1, ax=axes[0, 1], label='Temperature (Â°C)')\n",
    "\n",
    "# Elevation data\n",
    "elev_stats = calculate_comprehensive_stats(elev_data, elev_nodata, exclude_nodata=True)\n",
    "valid_elevs = elev_data[elev_data != elev_nodata]\n",
    "axes[1, 0].hist(valid_elevs, bins=30, alpha=0.7, color='brown', edgecolor='black')\n",
    "axes[1, 0].axvline(elev_stats['mean'], color='blue', linestyle='--', label=f\"Mean: {elev_stats['mean']:.0f}m\")\n",
    "axes[1, 0].axvline(elev_stats['median'], color='green', linestyle='--', label=f\"Median: {elev_stats['median']:.0f}m\")\n",
    "axes[1, 0].set_title('Elevation Distribution')\n",
    "axes[1, 0].set_xlabel('Elevation (m)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Elevation raster visualization\n",
    "elev_display = elev_data.copy().astype(float)\n",
    "elev_display[elev_display == elev_nodata] = np.nan\n",
    "im2 = axes[1, 1].imshow(elev_display, cmap='terrain', interpolation='nearest')\n",
    "axes[1, 1].set_title('Elevation Raster')\n",
    "plt.colorbar(im2, ax=axes[1, 1], label='Elevation (m)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== ELEVATION STATISTICS ===\")\n",
    "for key, value in elev_stats.items():\n",
    "    if value is not None and key in ['min', 'max', 'mean', 'median', 'std', 'range', 'percentile_25', 'percentile_75']:\n",
    "        print(f\"{key}: {value:.0f}m\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Working with Different Data Types\n",
    "\n",
    "Different raster data types require different statistical approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare statistics for different data types\n",
    "print(\"=== DATA TYPE COMPARISON ===\")\n",
    "print(\"\\nTemperature data (float32):\")\n",
    "print(f\"  Data type: {temp_data.dtype}\")\n",
    "print(f\"  Precision: Decimal places preserved\")\n",
    "print(f\"  Mean: {temp_stats['mean']:.6f}Â°C\")\n",
    "\n",
    "print(\"\\nElevation data (int16):\")\n",
    "print(f\"  Data type: {elev_data.dtype}\")\n",
    "print(f\"  Precision: Whole numbers only\")\n",
    "print(f\"  Mean: {elev_stats['mean']:.6f}m\")\n",
    "\n",
    "# Demonstrate precision differences\n",
    "print(\"\\n=== PRECISION IMPACT ===\")\n",
    "print(f\"Temperature std dev: {temp_stats['std']:.6f}Â°C (high precision)\")\n",
    "print(f\"Elevation std dev: {elev_stats['std']:.6f}m (limited by integer storage)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building the Complete Function\n",
    "\n",
    "### 3.1 Function Implementation Template\n",
    "\n",
    "Now let's build the complete `calculate_raster_statistics` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_raster_statistics_example(raster_path: str, band_number: int = 1, \n",
    "                                      exclude_nodata: bool = True) -> Dict[str, float]:\n",
    "    \"\"\"Example implementation of calculate_raster_statistics function.\"\"\"\n",
    "    \n",
    "    # Step 1: Open the raster file\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        \n",
    "        # Step 2: Read the specified band\n",
    "        data = src.read(band_number)\n",
    "        nodata_value = src.nodata\n",
    "        \n",
    "        # Step 3: Handle nodata values\n",
    "        if exclude_nodata and nodata_value is not None:\n",
    "            valid_mask = data != nodata_value\n",
    "            valid_data = data[valid_mask]\n",
    "        else:\n",
    "            valid_data = data.flatten()\n",
    "        \n",
    "        # Step 4: Calculate pixel counts\n",
    "        total_pixels = data.size\n",
    "        valid_pixels = len(valid_data)\n",
    "        nodata_pixels = total_pixels - valid_pixels\n",
    "        \n",
    "        # Step 5: Calculate statistics (handle case with no valid data)\n",
    "        if valid_pixels == 0:\n",
    "            return {\n",
    "                'min': None, 'max': None, 'mean': None, 'median': None,\n",
    "                'std': None, 'range': None, 'percentile_25': None, 'percentile_75': None,\n",
    "                'valid_pixels': float(valid_pixels), 'total_pixels': float(total_pixels), \n",
    "                'nodata_pixels': float(nodata_pixels)\n",
    "            }\n",
    "        \n",
    "        # Step 6: Calculate all required statistics\n",
    "        statistics = {\n",
    "            'min': float(np.min(valid_data)),\n",
    "            'max': float(np.max(valid_data)),\n",
    "            'mean': float(np.mean(valid_data)),\n",
    "            'median': float(np.median(valid_data)),\n",
    "            'std': float(np.std(valid_data)),\n",
    "            'range': float(np.ptp(valid_data)),  # peak-to-peak\n",
    "            'percentile_25': float(np.percentile(valid_data, 25)),\n",
    "            'percentile_75': float(np.percentile(valid_data, 75)),\n",
    "            'valid_pixels': float(valid_pixels),\n",
    "            'total_pixels': float(total_pixels),\n",
    "            'nodata_pixels': float(nodata_pixels)\n",
    "        }\n",
    "        \n",
    "        return statistics\n",
    "\n",
    "# Test the function with both datasets\n",
    "print(\"=== FUNCTION TEST RESULTS ===\")\n",
    "\n",
    "temp_result = calculate_raster_statistics_example(temp_raster, band_number=1)\n",
    "print(\"\\nTemperature statistics:\")\n",
    "for key, value in temp_result.items():\n",
    "    if isinstance(value, float) and value is not None:\n",
    "        if 'pixels' in key:\n",
    "            print(f\"  {key}: {value:.0f}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "elev_result = calculate_raster_statistics_example(elev_raster, band_number=1)\n",
    "print(\"\\nElevation statistics:\")\n",
    "for key, value in elev_result.items():\n",
    "    if isinstance(value, float) and value is not None:\n",
    "        if 'pixels' in key:\n",
    "            print(f\"  {key}: {value:.0f}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Testing Edge Cases\n",
    "\n",
    "Professional code must handle edge cases gracefully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different exclude_nodata settings\n",
    "print(\"=== EDGE CASE TESTING ===\")\n",
    "\n",
    "# Test 1: Include NoData values\n",
    "temp_with_nodata = calculate_raster_statistics_example(temp_raster, exclude_nodata=False)\n",
    "print(\"\\nTemperature WITH NoData included:\")\n",
    "print(f\"  Min: {temp_with_nodata['min']:.2f} (includes NoData!)\")\n",
    "print(f\"  Mean: {temp_with_nodata['mean']:.2f} (skewed by NoData!)\")\n",
    "\n",
    "# Test 2: Exclude NoData values (correct approach)\n",
    "temp_without_nodata = calculate_raster_statistics_example(temp_raster, exclude_nodata=True)\n",
    "print(\"\\nTemperature WITHOUT NoData (correct):\")\n",
    "print(f\"  Min: {temp_without_nodata['min']:.2f}Â°C\")\n",
    "print(f\"  Mean: {temp_without_nodata['mean']:.2f}Â°C\")\n",
    "\n",
    "# Test 3: Different bands (if available)\n",
    "print(f\"\\nData completeness comparison:\")\n",
    "print(f\"Temperature: {temp_without_nodata['valid_pixels']:.0f}/{temp_without_nodata['total_pixels']:.0f} valid pixels ({100*temp_without_nodata['valid_pixels']/temp_without_nodata['total_pixels']:.1f}%)\")\n",
    "print(f\"Elevation: {elev_result['valid_pixels']:.0f}/{elev_result['total_pixels']:.0f} valid pixels ({100*elev_result['valid_pixels']/elev_result['total_pixels']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Your Implementation Task\n",
    "\n",
    "### 4.1 Implementation Guidelines\n",
    "\n",
    "Now implement this function in `src/rasterio_basics.py`. Key implementation steps:\n",
    "\n",
    "```python\n",
    "def calculate_raster_statistics(raster_path: str, band_number: int = 1,\n",
    "                               exclude_nodata: bool = True) -> Dict[str, float]:\n",
    "    # TODO: Implement this function\n",
    "    #\n",
    "    # STEP 1: Open the raster file\n",
    "    # HINT: Use rasterio.open() with 'with' statement\n",
    "    #\n",
    "    # STEP 2: Read the specified band as a numpy array\n",
    "    # HINT: Use dataset.read(band_number) to get the data\n",
    "    #\n",
    "    # STEP 3: Handle nodata values\n",
    "    # HINT: Get nodata value with dataset.nodata\n",
    "    # HINT: Create a mask for valid data if exclude_nodata is True\n",
    "    #\n",
    "    # STEP 4: Calculate basic statistics\n",
    "    # HINT: Use numpy functions like np.min(), np.max(), np.mean(), np.std()\n",
    "    # HINT: Use np.median() and np.percentile() for additional stats\n",
    "    #\n",
    "    # STEP 5: Count pixels (total, valid, nodata)\n",
    "    # HINT: Use array.size for total, np.
